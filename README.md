# ğŸ§¬ scLLM: Single-Cell Large Language Models for Cell Type Prediction

scLLM is a single-cell transcriptomics tool that uses cell intrinsic rank ordered gene expression as sentences to train and use large language models (LLMs) for predicting cell types with high accuracy. It leverages the state-of-the-art (SOTA) architectures and the Hugging Face Transformers library to create a powerful and effective pipeline for annotating single-cell RNA-seq data.

## âš¡ï¸ Features

- ğŸ§ª Takes advantage of SOTA architectures such as GPT-2 and T5 for cell type prediction
- ğŸ“ Uses cell intrinsic rank ordered gene expression as sentences
- ğŸ¯ High accuracy cell type prediction
- ğŸ› ï¸ Easy-to-use API with customizable options
- ğŸ¤— Built on top of the Hugging Face Transformers library and PyTorch

## ğŸ“¦ Installation

```bash
git clone https://github.com/jzinno/scLLM.git
cd scLLM
pip install -r requirements.txt

```

## ğŸ¤ Contributing

We welcome contributions! Please read our Contributing Guidelines before submitting a pull request or opening an issue.

## ğŸ“„ License

scLLM is released under the _*PLACEHOLDER*_.
