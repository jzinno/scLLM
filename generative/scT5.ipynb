{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy\n",
    "import cell2sentence\n",
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer, AutoTokenizer\n",
    "from datasets import load_dataset, Dataset\n",
    "import evaluate\n",
    "import nltk\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\johnz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eso = scanpy.read_h5ad(\"../data/TabulaSapiens.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tissue_in_publication</th>\n",
       "      <th>assay_ontology_term_id</th>\n",
       "      <th>donor_id</th>\n",
       "      <th>anatomical_information</th>\n",
       "      <th>n_counts_UMIs</th>\n",
       "      <th>n_genes</th>\n",
       "      <th>cell_ontology_class</th>\n",
       "      <th>free_annotation</th>\n",
       "      <th>manually_annotated</th>\n",
       "      <th>compartment</th>\n",
       "      <th>...</th>\n",
       "      <th>tissue_ontology_term_id</th>\n",
       "      <th>suspension_type</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>assay</th>\n",
       "      <th>disease</th>\n",
       "      <th>organism</th>\n",
       "      <th>sex</th>\n",
       "      <th>tissue</th>\n",
       "      <th>self_reported_ethnicity</th>\n",
       "      <th>development_stage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAACCCACACTCCTGT_TSP6_Liver_NA_10X_1_1</th>\n",
       "      <td>Liver</td>\n",
       "      <td>EFO:0009922</td>\n",
       "      <td>TSP6</td>\n",
       "      <td>nan</td>\n",
       "      <td>7633.0</td>\n",
       "      <td>2259</td>\n",
       "      <td>macrophage</td>\n",
       "      <td>Monocyte/Macrophage</td>\n",
       "      <td>True</td>\n",
       "      <td>immune</td>\n",
       "      <td>...</td>\n",
       "      <td>UBERON:0002107</td>\n",
       "      <td>cell</td>\n",
       "      <td>macrophage</td>\n",
       "      <td>10x 3' v3</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>male</td>\n",
       "      <td>liver</td>\n",
       "      <td>European</td>\n",
       "      <td>67-year-old human stage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACGAAGTACCAGAG_TSP6_Liver_NA_10X_1_1</th>\n",
       "      <td>Liver</td>\n",
       "      <td>EFO:0009922</td>\n",
       "      <td>TSP6</td>\n",
       "      <td>nan</td>\n",
       "      <td>2858.0</td>\n",
       "      <td>1152</td>\n",
       "      <td>monocyte</td>\n",
       "      <td>Monocyte</td>\n",
       "      <td>True</td>\n",
       "      <td>immune</td>\n",
       "      <td>...</td>\n",
       "      <td>UBERON:0002107</td>\n",
       "      <td>cell</td>\n",
       "      <td>monocyte</td>\n",
       "      <td>10x 3' v3</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>male</td>\n",
       "      <td>liver</td>\n",
       "      <td>European</td>\n",
       "      <td>67-year-old human stage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACGCTCAACGGCTC_TSP6_Liver_NA_10X_1_1</th>\n",
       "      <td>Liver</td>\n",
       "      <td>EFO:0009922</td>\n",
       "      <td>TSP6</td>\n",
       "      <td>nan</td>\n",
       "      <td>7787.0</td>\n",
       "      <td>2983</td>\n",
       "      <td>endothelial cell of hepatic sinusoid</td>\n",
       "      <td>Endothelial</td>\n",
       "      <td>True</td>\n",
       "      <td>endothelial</td>\n",
       "      <td>...</td>\n",
       "      <td>UBERON:0002107</td>\n",
       "      <td>cell</td>\n",
       "      <td>endothelial cell of hepatic sinusoid</td>\n",
       "      <td>10x 3' v3</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>male</td>\n",
       "      <td>liver</td>\n",
       "      <td>European</td>\n",
       "      <td>67-year-old human stage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAGAACAGCCTCTTC_TSP6_Liver_NA_10X_1_1</th>\n",
       "      <td>Liver</td>\n",
       "      <td>EFO:0009922</td>\n",
       "      <td>TSP6</td>\n",
       "      <td>nan</td>\n",
       "      <td>10395.0</td>\n",
       "      <td>2598</td>\n",
       "      <td>macrophage</td>\n",
       "      <td>Monocyte/Macrophage</td>\n",
       "      <td>True</td>\n",
       "      <td>immune</td>\n",
       "      <td>...</td>\n",
       "      <td>UBERON:0002107</td>\n",
       "      <td>cell</td>\n",
       "      <td>macrophage</td>\n",
       "      <td>10x 3' v3</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>male</td>\n",
       "      <td>liver</td>\n",
       "      <td>European</td>\n",
       "      <td>67-year-old human stage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAGAACGTAGCACAG_TSP6_Liver_NA_10X_1_1</th>\n",
       "      <td>Liver</td>\n",
       "      <td>EFO:0009922</td>\n",
       "      <td>TSP6</td>\n",
       "      <td>nan</td>\n",
       "      <td>6610.0</td>\n",
       "      <td>2125</td>\n",
       "      <td>liver dendritic cell</td>\n",
       "      <td>Dendritic cell</td>\n",
       "      <td>True</td>\n",
       "      <td>immune</td>\n",
       "      <td>...</td>\n",
       "      <td>UBERON:0002107</td>\n",
       "      <td>cell</td>\n",
       "      <td>liver dendritic cell</td>\n",
       "      <td>10x 3' v3</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>male</td>\n",
       "      <td>liver</td>\n",
       "      <td>European</td>\n",
       "      <td>67-year-old human stage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSP2_Vasculature_aorta_SS2_B114577_B133059_Endothelial_P4_S364</th>\n",
       "      <td>Vasculature</td>\n",
       "      <td>EFO:0008931</td>\n",
       "      <td>TSP2</td>\n",
       "      <td>aorta</td>\n",
       "      <td>13205.0</td>\n",
       "      <td>579</td>\n",
       "      <td>endothelial cell</td>\n",
       "      <td>endothelial cell</td>\n",
       "      <td>True</td>\n",
       "      <td>endothelial</td>\n",
       "      <td>...</td>\n",
       "      <td>UBERON:0000947</td>\n",
       "      <td>cell</td>\n",
       "      <td>endothelial cell</td>\n",
       "      <td>Smart-seq2</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>female</td>\n",
       "      <td>aorta</td>\n",
       "      <td>African American or Afro-Caribbean</td>\n",
       "      <td>61-year-old human stage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSP2_Vasculature_aorta_SS2_B114577_B133059_Endothelial_P5_S365</th>\n",
       "      <td>Vasculature</td>\n",
       "      <td>EFO:0008931</td>\n",
       "      <td>TSP2</td>\n",
       "      <td>aorta</td>\n",
       "      <td>9565.0</td>\n",
       "      <td>529</td>\n",
       "      <td>endothelial cell</td>\n",
       "      <td>endothelial cell</td>\n",
       "      <td>True</td>\n",
       "      <td>endothelial</td>\n",
       "      <td>...</td>\n",
       "      <td>UBERON:0000947</td>\n",
       "      <td>cell</td>\n",
       "      <td>endothelial cell</td>\n",
       "      <td>Smart-seq2</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>female</td>\n",
       "      <td>aorta</td>\n",
       "      <td>African American or Afro-Caribbean</td>\n",
       "      <td>61-year-old human stage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSP2_Vasculature_aorta_SS2_B114577_B133059_Endothelial_P7_S367</th>\n",
       "      <td>Vasculature</td>\n",
       "      <td>EFO:0008931</td>\n",
       "      <td>TSP2</td>\n",
       "      <td>aorta</td>\n",
       "      <td>195639.0</td>\n",
       "      <td>2753</td>\n",
       "      <td>endothelial cell</td>\n",
       "      <td>endothelial cell</td>\n",
       "      <td>True</td>\n",
       "      <td>endothelial</td>\n",
       "      <td>...</td>\n",
       "      <td>UBERON:0000947</td>\n",
       "      <td>cell</td>\n",
       "      <td>endothelial cell</td>\n",
       "      <td>Smart-seq2</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>female</td>\n",
       "      <td>aorta</td>\n",
       "      <td>African American or Afro-Caribbean</td>\n",
       "      <td>61-year-old human stage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSP2_Vasculature_aorta_SS2_B114577_B133059_Endothelial_P8_S368</th>\n",
       "      <td>Vasculature</td>\n",
       "      <td>EFO:0008931</td>\n",
       "      <td>TSP2</td>\n",
       "      <td>aorta</td>\n",
       "      <td>37260.0</td>\n",
       "      <td>984</td>\n",
       "      <td>endothelial cell</td>\n",
       "      <td>endothelial cell</td>\n",
       "      <td>True</td>\n",
       "      <td>endothelial</td>\n",
       "      <td>...</td>\n",
       "      <td>UBERON:0000947</td>\n",
       "      <td>cell</td>\n",
       "      <td>endothelial cell</td>\n",
       "      <td>Smart-seq2</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>female</td>\n",
       "      <td>aorta</td>\n",
       "      <td>African American or Afro-Caribbean</td>\n",
       "      <td>61-year-old human stage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSP2_Vasculature_aorta_SS2_B114577_B133059_Endothelial_P9_S369</th>\n",
       "      <td>Vasculature</td>\n",
       "      <td>EFO:0008931</td>\n",
       "      <td>TSP2</td>\n",
       "      <td>aorta</td>\n",
       "      <td>63837.0</td>\n",
       "      <td>1509</td>\n",
       "      <td>endothelial cell</td>\n",
       "      <td>endothelial cell</td>\n",
       "      <td>True</td>\n",
       "      <td>endothelial</td>\n",
       "      <td>...</td>\n",
       "      <td>UBERON:0000947</td>\n",
       "      <td>cell</td>\n",
       "      <td>endothelial cell</td>\n",
       "      <td>Smart-seq2</td>\n",
       "      <td>normal</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>female</td>\n",
       "      <td>aorta</td>\n",
       "      <td>African American or Afro-Caribbean</td>\n",
       "      <td>61-year-old human stage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>483152 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tissue_in_publication  \\\n",
       "cell_id                                                                    \n",
       "AAACCCACACTCCTGT_TSP6_Liver_NA_10X_1_1                             Liver   \n",
       "AAACGAAGTACCAGAG_TSP6_Liver_NA_10X_1_1                             Liver   \n",
       "AAACGCTCAACGGCTC_TSP6_Liver_NA_10X_1_1                             Liver   \n",
       "AAAGAACAGCCTCTTC_TSP6_Liver_NA_10X_1_1                             Liver   \n",
       "AAAGAACGTAGCACAG_TSP6_Liver_NA_10X_1_1                             Liver   \n",
       "...                                                                  ...   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...           Vasculature   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...           Vasculature   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...           Vasculature   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...           Vasculature   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...           Vasculature   \n",
       "\n",
       "                                                   assay_ontology_term_id  \\\n",
       "cell_id                                                                     \n",
       "AAACCCACACTCCTGT_TSP6_Liver_NA_10X_1_1                        EFO:0009922   \n",
       "AAACGAAGTACCAGAG_TSP6_Liver_NA_10X_1_1                        EFO:0009922   \n",
       "AAACGCTCAACGGCTC_TSP6_Liver_NA_10X_1_1                        EFO:0009922   \n",
       "AAAGAACAGCCTCTTC_TSP6_Liver_NA_10X_1_1                        EFO:0009922   \n",
       "AAAGAACGTAGCACAG_TSP6_Liver_NA_10X_1_1                        EFO:0009922   \n",
       "...                                                                   ...   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...            EFO:0008931   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...            EFO:0008931   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...            EFO:0008931   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...            EFO:0008931   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...            EFO:0008931   \n",
       "\n",
       "                                                   donor_id  \\\n",
       "cell_id                                                       \n",
       "AAACCCACACTCCTGT_TSP6_Liver_NA_10X_1_1                 TSP6   \n",
       "AAACGAAGTACCAGAG_TSP6_Liver_NA_10X_1_1                 TSP6   \n",
       "AAACGCTCAACGGCTC_TSP6_Liver_NA_10X_1_1                 TSP6   \n",
       "AAAGAACAGCCTCTTC_TSP6_Liver_NA_10X_1_1                 TSP6   \n",
       "AAAGAACGTAGCACAG_TSP6_Liver_NA_10X_1_1                 TSP6   \n",
       "...                                                     ...   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...     TSP2   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...     TSP2   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...     TSP2   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...     TSP2   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...     TSP2   \n",
       "\n",
       "                                                   anatomical_information  \\\n",
       "cell_id                                                                     \n",
       "AAACCCACACTCCTGT_TSP6_Liver_NA_10X_1_1                                nan   \n",
       "AAACGAAGTACCAGAG_TSP6_Liver_NA_10X_1_1                                nan   \n",
       "AAACGCTCAACGGCTC_TSP6_Liver_NA_10X_1_1                                nan   \n",
       "AAAGAACAGCCTCTTC_TSP6_Liver_NA_10X_1_1                                nan   \n",
       "AAAGAACGTAGCACAG_TSP6_Liver_NA_10X_1_1                                nan   \n",
       "...                                                                   ...   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...                  aorta   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...                  aorta   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...                  aorta   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...                  aorta   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...                  aorta   \n",
       "\n",
       "                                                    n_counts_UMIs  n_genes  \\\n",
       "cell_id                                                                      \n",
       "AAACCCACACTCCTGT_TSP6_Liver_NA_10X_1_1                     7633.0     2259   \n",
       "AAACGAAGTACCAGAG_TSP6_Liver_NA_10X_1_1                     2858.0     1152   \n",
       "AAACGCTCAACGGCTC_TSP6_Liver_NA_10X_1_1                     7787.0     2983   \n",
       "AAAGAACAGCCTCTTC_TSP6_Liver_NA_10X_1_1                    10395.0     2598   \n",
       "AAAGAACGTAGCACAG_TSP6_Liver_NA_10X_1_1                     6610.0     2125   \n",
       "...                                                           ...      ...   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...        13205.0      579   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...         9565.0      529   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...       195639.0     2753   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...        37260.0      984   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...        63837.0     1509   \n",
       "\n",
       "                                                                     cell_ontology_class  \\\n",
       "cell_id                                                                                    \n",
       "AAACCCACACTCCTGT_TSP6_Liver_NA_10X_1_1                                        macrophage   \n",
       "AAACGAAGTACCAGAG_TSP6_Liver_NA_10X_1_1                                          monocyte   \n",
       "AAACGCTCAACGGCTC_TSP6_Liver_NA_10X_1_1              endothelial cell of hepatic sinusoid   \n",
       "AAAGAACAGCCTCTTC_TSP6_Liver_NA_10X_1_1                                        macrophage   \n",
       "AAAGAACGTAGCACAG_TSP6_Liver_NA_10X_1_1                              liver dendritic cell   \n",
       "...                                                                                  ...   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...                      endothelial cell   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...                      endothelial cell   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...                      endothelial cell   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...                      endothelial cell   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...                      endothelial cell   \n",
       "\n",
       "                                                        free_annotation  \\\n",
       "cell_id                                                                   \n",
       "AAACCCACACTCCTGT_TSP6_Liver_NA_10X_1_1              Monocyte/Macrophage   \n",
       "AAACGAAGTACCAGAG_TSP6_Liver_NA_10X_1_1                         Monocyte   \n",
       "AAACGCTCAACGGCTC_TSP6_Liver_NA_10X_1_1                      Endothelial   \n",
       "AAAGAACAGCCTCTTC_TSP6_Liver_NA_10X_1_1              Monocyte/Macrophage   \n",
       "AAAGAACGTAGCACAG_TSP6_Liver_NA_10X_1_1                   Dendritic cell   \n",
       "...                                                                 ...   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...     endothelial cell   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...     endothelial cell   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...     endothelial cell   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...     endothelial cell   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...     endothelial cell   \n",
       "\n",
       "                                                    manually_annotated  \\\n",
       "cell_id                                                                  \n",
       "AAACCCACACTCCTGT_TSP6_Liver_NA_10X_1_1                            True   \n",
       "AAACGAAGTACCAGAG_TSP6_Liver_NA_10X_1_1                            True   \n",
       "AAACGCTCAACGGCTC_TSP6_Liver_NA_10X_1_1                            True   \n",
       "AAAGAACAGCCTCTTC_TSP6_Liver_NA_10X_1_1                            True   \n",
       "AAAGAACGTAGCACAG_TSP6_Liver_NA_10X_1_1                            True   \n",
       "...                                                                ...   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...                True   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...                True   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...                True   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...                True   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...                True   \n",
       "\n",
       "                                                    compartment  ...  \\\n",
       "cell_id                                                          ...   \n",
       "AAACCCACACTCCTGT_TSP6_Liver_NA_10X_1_1                   immune  ...   \n",
       "AAACGAAGTACCAGAG_TSP6_Liver_NA_10X_1_1                   immune  ...   \n",
       "AAACGCTCAACGGCTC_TSP6_Liver_NA_10X_1_1              endothelial  ...   \n",
       "AAAGAACAGCCTCTTC_TSP6_Liver_NA_10X_1_1                   immune  ...   \n",
       "AAAGAACGTAGCACAG_TSP6_Liver_NA_10X_1_1                   immune  ...   \n",
       "...                                                         ...  ...   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...  endothelial  ...   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...  endothelial  ...   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...  endothelial  ...   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...  endothelial  ...   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...  endothelial  ...   \n",
       "\n",
       "                                                   tissue_ontology_term_id  \\\n",
       "cell_id                                                                      \n",
       "AAACCCACACTCCTGT_TSP6_Liver_NA_10X_1_1                      UBERON:0002107   \n",
       "AAACGAAGTACCAGAG_TSP6_Liver_NA_10X_1_1                      UBERON:0002107   \n",
       "AAACGCTCAACGGCTC_TSP6_Liver_NA_10X_1_1                      UBERON:0002107   \n",
       "AAAGAACAGCCTCTTC_TSP6_Liver_NA_10X_1_1                      UBERON:0002107   \n",
       "AAAGAACGTAGCACAG_TSP6_Liver_NA_10X_1_1                      UBERON:0002107   \n",
       "...                                                                    ...   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...          UBERON:0000947   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...          UBERON:0000947   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...          UBERON:0000947   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...          UBERON:0000947   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...          UBERON:0000947   \n",
       "\n",
       "                                                    suspension_type  \\\n",
       "cell_id                                                               \n",
       "AAACCCACACTCCTGT_TSP6_Liver_NA_10X_1_1                         cell   \n",
       "AAACGAAGTACCAGAG_TSP6_Liver_NA_10X_1_1                         cell   \n",
       "AAACGCTCAACGGCTC_TSP6_Liver_NA_10X_1_1                         cell   \n",
       "AAAGAACAGCCTCTTC_TSP6_Liver_NA_10X_1_1                         cell   \n",
       "AAAGAACGTAGCACAG_TSP6_Liver_NA_10X_1_1                         cell   \n",
       "...                                                             ...   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...             cell   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...             cell   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...             cell   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...             cell   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...             cell   \n",
       "\n",
       "                                                                               cell_type  \\\n",
       "cell_id                                                                                    \n",
       "AAACCCACACTCCTGT_TSP6_Liver_NA_10X_1_1                                        macrophage   \n",
       "AAACGAAGTACCAGAG_TSP6_Liver_NA_10X_1_1                                          monocyte   \n",
       "AAACGCTCAACGGCTC_TSP6_Liver_NA_10X_1_1              endothelial cell of hepatic sinusoid   \n",
       "AAAGAACAGCCTCTTC_TSP6_Liver_NA_10X_1_1                                        macrophage   \n",
       "AAAGAACGTAGCACAG_TSP6_Liver_NA_10X_1_1                              liver dendritic cell   \n",
       "...                                                                                  ...   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...                      endothelial cell   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...                      endothelial cell   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...                      endothelial cell   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...                      endothelial cell   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...                      endothelial cell   \n",
       "\n",
       "                                                         assay disease  \\\n",
       "cell_id                                                                  \n",
       "AAACCCACACTCCTGT_TSP6_Liver_NA_10X_1_1               10x 3' v3  normal   \n",
       "AAACGAAGTACCAGAG_TSP6_Liver_NA_10X_1_1               10x 3' v3  normal   \n",
       "AAACGCTCAACGGCTC_TSP6_Liver_NA_10X_1_1               10x 3' v3  normal   \n",
       "AAAGAACAGCCTCTTC_TSP6_Liver_NA_10X_1_1               10x 3' v3  normal   \n",
       "AAAGAACGTAGCACAG_TSP6_Liver_NA_10X_1_1               10x 3' v3  normal   \n",
       "...                                                        ...     ...   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...  Smart-seq2  normal   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...  Smart-seq2  normal   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...  Smart-seq2  normal   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...  Smart-seq2  normal   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...  Smart-seq2  normal   \n",
       "\n",
       "                                                        organism     sex  \\\n",
       "cell_id                                                                    \n",
       "AAACCCACACTCCTGT_TSP6_Liver_NA_10X_1_1              Homo sapiens    male   \n",
       "AAACGAAGTACCAGAG_TSP6_Liver_NA_10X_1_1              Homo sapiens    male   \n",
       "AAACGCTCAACGGCTC_TSP6_Liver_NA_10X_1_1              Homo sapiens    male   \n",
       "AAAGAACAGCCTCTTC_TSP6_Liver_NA_10X_1_1              Homo sapiens    male   \n",
       "AAAGAACGTAGCACAG_TSP6_Liver_NA_10X_1_1              Homo sapiens    male   \n",
       "...                                                          ...     ...   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...  Homo sapiens  female   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...  Homo sapiens  female   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...  Homo sapiens  female   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...  Homo sapiens  female   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...  Homo sapiens  female   \n",
       "\n",
       "                                                   tissue  \\\n",
       "cell_id                                                     \n",
       "AAACCCACACTCCTGT_TSP6_Liver_NA_10X_1_1              liver   \n",
       "AAACGAAGTACCAGAG_TSP6_Liver_NA_10X_1_1              liver   \n",
       "AAACGCTCAACGGCTC_TSP6_Liver_NA_10X_1_1              liver   \n",
       "AAAGAACAGCCTCTTC_TSP6_Liver_NA_10X_1_1              liver   \n",
       "AAAGAACGTAGCACAG_TSP6_Liver_NA_10X_1_1              liver   \n",
       "...                                                   ...   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...  aorta   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...  aorta   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...  aorta   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...  aorta   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...  aorta   \n",
       "\n",
       "                                                               self_reported_ethnicity  \\\n",
       "cell_id                                                                                  \n",
       "AAACCCACACTCCTGT_TSP6_Liver_NA_10X_1_1                                        European   \n",
       "AAACGAAGTACCAGAG_TSP6_Liver_NA_10X_1_1                                        European   \n",
       "AAACGCTCAACGGCTC_TSP6_Liver_NA_10X_1_1                                        European   \n",
       "AAAGAACAGCCTCTTC_TSP6_Liver_NA_10X_1_1                                        European   \n",
       "AAAGAACGTAGCACAG_TSP6_Liver_NA_10X_1_1                                        European   \n",
       "...                                                                                ...   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...  African American or Afro-Caribbean   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...  African American or Afro-Caribbean   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...  African American or Afro-Caribbean   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...  African American or Afro-Caribbean   \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...  African American or Afro-Caribbean   \n",
       "\n",
       "                                                          development_stage  \n",
       "cell_id                                                                      \n",
       "AAACCCACACTCCTGT_TSP6_Liver_NA_10X_1_1              67-year-old human stage  \n",
       "AAACGAAGTACCAGAG_TSP6_Liver_NA_10X_1_1              67-year-old human stage  \n",
       "AAACGCTCAACGGCTC_TSP6_Liver_NA_10X_1_1              67-year-old human stage  \n",
       "AAAGAACAGCCTCTTC_TSP6_Liver_NA_10X_1_1              67-year-old human stage  \n",
       "AAAGAACGTAGCACAG_TSP6_Liver_NA_10X_1_1              67-year-old human stage  \n",
       "...                                                                     ...  \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...  61-year-old human stage  \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...  61-year-old human stage  \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...  61-year-old human stage  \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...  61-year-old human stage  \n",
       "TSP2_Vasculature_aorta_SS2_B114577_B133059_Endo...  61-year-old human stage  \n",
       "\n",
       "[483152 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eso.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 483152/483152 [05:09<00:00, 1562.13it/s]\n"
     ]
    }
   ],
   "source": [
    "eso_c2s = cell2sentence.transforms.csdata_from_adata(eso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_sents = eso_c2s.create_sentence_lists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = eso.obs['cell_type'].values\n",
    "labels = [str(label) for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = dict(enumerate(np.unique(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(eso, eso_c2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell_sents = [inner_list[:300] for inner_list in cell_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_sents = [' '.join(inner_list) for inner_list in cell_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas DataFrame with the sentences and labels\n",
    "data = {\"text\": cell_sents, \"cell_type\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(cell_sents, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset from the pandas DataFrame\n",
    "dataset = Dataset.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'cell_type'],\n",
       "    num_rows: 458994\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c6ec44ea414e5ab9b191d1b2eeb1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/459 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "19332838191"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'].to_json(\"../data/TabulaSapiens_raw_dataset_train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c30e6d6e20417983dc2315d8f871f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1015088121"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'].to_json(\"../data/TabulaSapiens_raw_dataset_test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('json', data_files={'train': '../data/TabulaSapiens_raw_dataset_train.json','test': '../data/TabulaSapiens_raw_dataset_test.json\"'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'cell_type'],\n",
       "    num_rows: 483152\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('../data/TabulaSapiens_raw_dataset.pkl', 'wb') as f:\n",
    "#    pickle.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = pickle.load(open('../data/TabulaSapiens_raw_dataset.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\johnz\\anaconda3\\envs\\celldl\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "prefix = \"label cell type: \"\n",
    "max_input_length = 512\n",
    "max_target_length = 64\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
    "\n",
    "def preprocess_data(examples):\n",
    "  inputs = [prefix + text for text in examples[\"text\"]]\n",
    "  model_inputs = tokenizer(inputs, max_length=max_input_length, padding=True, truncation=True)\n",
    "\n",
    "  # Setup the tokenizer for targets\n",
    "  with tokenizer.as_target_tokenizer():\n",
    "    labels = tokenizer(examples[\"cell_type\"], max_length=max_target_length, padding=True, truncation=True)\n",
    "\n",
    "  model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "  return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'cell_type'],\n",
       "    num_rows: 87947\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'ENSG00000245975 ENSG00000264112 ENSG00000213305 ENSG00000129682 ENSG00000241535 ENSG00000272717 ENSG00000239827 ENSG00000212195 ENSG00000198618 ENSG00000148735 ENSG00000199568 ENSG00000273254 ENSG00000246100 ENSG00000167333 ENSG00000272750 ENSG00000243725 ENSG00000272908 ENSG00000286071 ENSG00000249936 ENSG00000050628 ENSG00000280088 ENSG00000285646 ENSG00000269313 ENSG00000267278 ENSG00000154548 ENSG00000285725 ENSG00000185480 ENSG00000233230 ENSG00000243406 ENSG00000263069 ENSG00000266962 ENSG00000174032 ENSG00000279529 ENSG00000177103 ENSG00000200156 ENSG00000211813 ENSG00000267254 ENSG00000260318 ENSG00000233328 ENSG00000274156 ENSG00000261586 ENSG00000180815 ENSG00000174876 ENSG00000272370 ENSG00000013619 ENSG00000286268 ENSG00000187733 ENSG00000109881 ENSG00000165238 ENSG00000271856 ENSG00000171574 ENSG00000166446 ENSG00000065491 ENSG00000189114 ENSG00000075336 ENSG00000165046 ENSG00000196437 ENSG00000137976 ENSG00000127081 ENSG00000187533 ENSG00000236778 ENSG00000163617 ENSG00000095397 ENSG00000117593 ENSG00000106692 ENSG00000176148 ENSG00000168280 ENSG00000071246 ENSG00000158156 ENSG00000125449 ENSG00000148297 ENSG00000198746 ENSG00000240370 ENSG00000181982 ENSG00000282851 ENSG00000164073 ENSG00000105559 ENSG00000206562 ENSG00000276141 ENSG00000112782 ENSG00000178537 ENSG00000135205 ENSG00000286129 ENSG00000274210 ENSG00000268027 ENSG00000100376 ENSG00000279078 ENSG00000137494 ENSG00000215158 ENSG00000061656 ENSG00000188542 ENSG00000196150 ENSG00000101417 ENSG00000101019 ENSG00000184402 ENSG00000204348 ENSG00000112640 ENSG00000104447 ENSG00000214106 ENSG00000266053 ENSG00000086200 ENSG00000275183 ENSG00000237945 ENSG00000185619 ENSG00000159733 ENSG00000170677 ENSG00000124160 ENSG00000021300 ENSG00000021776 ENSG00000074582 ENSG00000064703 ENSG00000167077 ENSG00000198270 ENSG00000139620 ENSG00000184208 ENSG00000087095 ENSG00000197077 ENSG00000154222 ENSG00000164187 ENSG00000259834 ENSG00000279541 ENSG00000041353 ENSG00000169964 ENSG00000117862 ENSG00000189136 ENSG00000187713 ENSG00000177685 ENSG00000184162 ENSG00000198042 ENSG00000146776 ENSG00000173085 ENSG00000205323 ENSG00000197283 ENSG00000117597 ENSG00000177034 ENSG00000078967 ENSG00000137628 ENSG00000142444 ENSG00000174842 ENSG00000111269 ENSG00000015676 ENSG00000122483 ENSG00000115109 ENSG00000137073 ENSG00000095319 ENSG00000073050 ENSG00000198863 ENSG00000125863 ENSG00000072736 ENSG00000135749 ENSG00000130856 ENSG00000230657 ENSG00000083123 ENSG00000165660 ENSG00000101138 ENSG00000114812 ENSG00000111727 ENSG00000264522 ENSG00000110888 ENSG00000186575 ENSG00000011260 ENSG00000026103 ENSG00000226471 ENSG00000137817 ENSG00000197563 ENSG00000177337 ENSG00000167186 ENSG00000134779 ENSG00000176102 ENSG00000136932 ENSG00000179526 ENSG00000108509 ENSG00000135148 ENSG00000122188 ENSG00000089094 ENSG00000166024 ENSG00000162607 ENSG00000196312 ENSG00000186141 ENSG00000189180 ENSG00000166313 ENSG00000137770 ENSG00000161204 ENSG00000134551 ENSG00000135930 ENSG00000165055 ENSG00000197870 ENSG00000130810 ENSG00000110315 ENSG00000172888 ENSG00000186205 ENSG00000116299 ENSG00000148187 ENSG00000147654 ENSG00000117090 ENSG00000008710 ENSG00000205649 ENSG00000126550 ENSG00000126549 ENSG00000137040 ENSG00000165806 ENSG00000145414 ENSG00000164151 ENSG00000170852 ENSG00000257704 ENSG00000001497 ENSG00000279765 ENSG00000026751 ENSG00000126461 ENSG00000137074 ENSG00000099308 ENSG00000160588 ENSG00000184545 ENSG00000121335 ENSG00000070785 ENSG00000172007 ENSG00000248092 ENSG00000113300 ENSG00000139323 ENSG00000065268 ENSG00000265354 ENSG00000105717 ENSG00000167081 ENSG00000163960 ENSG00000126464 ENSG00000164597 ENSG00000163607 ENSG00000215421 ENSG00000256043 ENSG00000214367 ENSG00000121957 ENSG00000171201 ENSG00000138172 ENSG00000139514 ENSG00000126214 ENSG00000198718 ENSG00000135049 ENSG00000099849 ENSG00000133302 ENSG00000066583 ENSG00000158636 ENSG00000111266 ENSG00000134545 ENSG00000140931 ENSG00000108389 ENSG00000134900 ENSG00000149792 ENSG00000156113 ENSG00000234127 ENSG00000153029 ENSG00000172175 ENSG00000119446 ENSG00000065357 ENSG00000152904 ENSG00000001631 ENSG00000112787 ENSG00000131771 ENSG00000172530 ENSG00000169155 ENSG00000117020 ENSG00000257093 ENSG00000251655 ENSG00000103064 ENSG00000118596 ENSG00000131437 ENSG00000092140 ENSG00000236278 ENSG00000116954 ENSG00000112763 ENSG00000182872 ENSG00000134318 ENSG00000186577 ENSG00000136247 ENSG00000169032 ENSG00000181458 ENSG00000144810 ENSG00000168566 ENSG00000166889 ENSG00000121104 ENSG00000099290 ENSG00000131148 ENSG00000213281 ENSG00000167721 ENSG00000148337 ENSG00000132604 ENSG00000016864 ENSG00000139428 ENSG00000170949 ENSG00000145293 ENSG00000179029 ENSG00000108599 ENSG00000183718 ENSG00000198911 ENSG00000213983 ENSG00000105127 ENSG00000161920 ENSG00000174501 ENSG00000126602 ENSG00000196547 ENSG00000167196 ENSG00000111450 ENSG00000136271 ENSG00000079134 ENSG00000162078 ENSG00000184436 ENSG00000246067 ENSG00000102125 ENSG00000112305 ENSG00000153214 ENSG00000154889 ENSG00000170266 ENSG00000160294 ENSG00000183207 ENSG00000032444 ENSG00000135070 ENSG00000091483 ENSG00000166454 ENSG00000126351 ENSG00000271503 ENSG00000152804 ENSG00000176624 ENSG00000174579 ENSG00000102225 ENSG00000225630 ENSG00000131149 ENSG00000135976 ENSG00000154174 ENSG00000077235 ENSG00000147592 ENSG00000117602 ENSG00000126804 ENSG00000198218 ENSG00000100258 ENSG00000204304 ENSG00000138663 ENSG00000131050 ENSG00000210184 ENSG00000165494 ENSG00000004142 ENSG00000111647 ENSG00000160216 ENSG00000134539 ENSG00000173812 ENSG00000126858 ENSG00000083168 ENSG00000154153 ENSG00000184205 ENSG00000102908 ENSG00000231887 ENSG00000147133 ENSG00000130935 ENSG00000151657 ENSG00000033030 ENSG00000131686 ENSG00000118495 ENSG00000104852 ENSG00000131634 ENSG00000140829 ENSG00000144228 ENSG00000110200 ENSG00000180233 ENSG00000082512 ENSG00000125354 ENSG00000148248 ENSG00000107957 ENSG00000125482 ENSG00000103111 ENSG00000154305 ENSG00000163655 ENSG00000182372 ENSG00000149089 ENSG00000093183 ENSG00000184432 ENSG00000133935 ENSG00000165669 ENSG00000070814 ENSG00000123545 ENSG00000007202 ENSG00000166855 ENSG00000111880 ENSG00000141682 ENSG00000087269 ENSG00000111726 ENSG00000143641 ENSG00000117614 ENSG00000043143 ENSG00000164056 ENSG00000116698 ENSG00000151923 ENSG00000116194 ENSG00000115875 ENSG00000196756 ENSG00000099991 ENSG00000173276 ENSG00000133112 ENSG00000197712 ENSG00000180357 ENSG00000198821 ENSG00000160862 ENSG00000174282 ENSG00000147687 ENSG00000006016 ENSG00000137075 ENSG00000279602 ENSG00000169609 ENSG00000164327 ENSG00000159763 ENSG00000113141 ENSG00000138032 ENSG00000163171 ENSG00000071189 ENSG00000110696 ENSG00000110172 ENSG00000145782 ENSG00000188994 ENSG00000132612 ENSG00000211459 ENSG00000127311 ENSG00000127663 ENSG00000120910 ENSG00000052723 ENSG00000175634 ENSG00000099917 ENSG00000177981 ENSG00000197217 ENSG00000151353 ENSG00000189306 ENSG00000177853 ENSG00000107537 ENSG00000140280 ENSG00000063978 ENSG00000164172 ENSG00000134243 ENSG00000031698 ENSG00000138801 ENSG00000116786 ENSG00000012660 ENSG00000210082 ENSG00000198643 ENSG00000128739 ENSG00000158615 ENSG00000090581 ENSG00000171735 ENSG00000139112 ENSG00000204220 ENSG00000153046 ENSG00000196305 ENSG00000059758 ENSG00000047249 ENSG00000119596 ENSG00000188529 ENSG00000168675 ENSG00000115364 ENSG00000157916 ENSG00000106392 ENSG00000134440 ENSG00000144867 ENSG00000006712 ENSG00000173327 ENSG00000130338 ENSG00000125734 ENSG00000113621 ENSG00000116984 ENSG00000166801 ENSG00000079335 ENSG00000168259 ENSG00000183049 ENSG00000103502 ENSG00000130813 ENSG00000089818 ENSG00000111707 ENSG00000185591 ENSG00000164105 ENSG00000138777 ENSG00000168884 ENSG00000114423 ENSG00000090615 ENSG00000119004 ENSG00000074370 ENSG00000067082 ENSG00000100425 ENSG00000166747 ENSG00000157106 ENSG00000173209 ENSG00000144909 ENSG00000172531 ENSG00000165219 ENSG00000124596 ENSG00000168564 ENSG00000108654 ENSG00000141030 ENSG00000197771 ENSG00000120697 ENSG00000138814 ENSG00000178104 ENSG00000204054 ENSG00000172086 ENSG00000074706 ENSG00000198862 ENSG00000198663 ENSG00000108021 ENSG00000221823 ENSG00000154640 ENSG00000054282 ENSG00000128272 ENSG00000115232 ENSG00000072803 ENSG00000151414 ENSG00000122218 ENSG00000198399 ENSG00000115806 ENSG00000137500 ENSG00000167772 ENSG00000085491 ENSG00000124795 ENSG00000107742 ENSG00000081154 ENSG00000100100 ENSG00000167699 ENSG00000170584 ENSG00000067057 ENSG00000217555 ENSG00000100823 ENSG00000265206 ENSG00000072210 ENSG00000132388 ENSG00000092199 ENSG00000164466 ENSG00000101294 ENSG00000078747 ENSG00000134242 ENSG00000123353 ENSG00000136718 ENSG00000142534 ENSG00000101236 ENSG00000149136 ENSG00000151092 ENSG00000153179 ENSG00000153094 ENSG00000078687 ENSG00000166974 ENSG00000111605 ENSG00000154217 ENSG00000174485 ENSG00000143155 ENSG00000140575 ENSG00000108528 ENSG00000066379 ENSG00000197063 ENSG00000153147 ENSG00000007080 ENSG00000198938 ENSG00000054116 ENSG00000101882 ENSG00000105887 ENSG00000135316 ENSG00000175701 ENSG00000183431 ENSG00000152484 ENSG00000082641 ENSG00000142188 ENSG00000015475 ENSG00000018189 ENSG00000109906 ENSG00000117054 ENSG00000185728 ENSG00000155850 ENSG00000125651 ENSG00000253729 ENSG00000015133 ENSG00000055609 ENSG00000132581 ENSG00000086598 ENSG00000182952 ENSG00000109854 ENSG00000146247 ENSG00000251562 ENSG00000204569 ENSG00000126581 ENSG00000139083 ENSG00000090470 ENSG00000119669 ENSG00000164308 ENSG00000054118 ENSG00000198804 ENSG00000116580 ENSG00000137818 ENSG00000167526 ENSG00000273559 ENSG00000103415 ENSG00000166037 ENSG00000156261 ENSG00000052802 ENSG00000120616 ENSG00000132842 ENSG00000024048 ENSG00000164163 ENSG00000079805 ENSG00000153113 ENSG00000136986 ENSG00000136938 ENSG00000204120 ENSG00000143376 ENSG00000163874 ENSG00000164587 ENSG00000138768 ENSG00000197622 ENSG00000228300 ENSG00000174173 ENSG00000182180 ENSG00000119314 ENSG00000061936 ENSG00000004700 ENSG00000142875 ENSG00000108091 ENSG00000151883 ENSG00000155744 ENSG00000156508 ENSG00000198171 ENSG00000110852 ENSG00000080802 ENSG00000204386 ENSG00000109606 ENSG00000159256 ENSG00000074319 ENSG00000125740 ENSG00000111832 ENSG00000242125 ENSG00000176386 ENSG00000134152 ENSG00000066777 ENSG00000132475 ENSG00000168118 ENSG00000135541 ENSG00000135046 ENSG00000132676 ENSG00000125944 ENSG00000125656 ENSG00000140332 ENSG00000171316 ENSG00000113263 ENSG00000107679 ENSG00000123136 ENSG00000166275 ENSG00000065882 ENSG00000196914 ENSG00000008441 ENSG00000247596 ENSG00000131508 ENSG00000089159 ENSG00000027075 ENSG00000204388 ENSG00000132780 ENSG00000180096 ENSG00000169641 ENSG00000004455 ENSG00000136485 ENSG00000183354 ENSG00000116871 ENSG00000171522 ENSG00000051620 ENSG00000166710 ENSG00000151702 ENSG00000114391 ENSG00000118579 ENSG00000204392 ENSG00000174946 ENSG00000117758 ENSG00000071462 ENSG00000165169 ENSG00000164674 ENSG00000080824 ENSG00000101901 ENSG00000152061 ENSG00000177479 ENSG00000115216 ENSG00000154001 ENSG00000144579 ENSG00000197157 ENSG00000135272 ENSG00000101577 ENSG00000183864 ENSG00000095015 ENSG00000077097 ENSG00000277734 ENSG00000168216 ENSG00000160633 ENSG00000196199 ENSG00000070831 ENSG00000121067 ENSG00000171206 ENSG00000058668 ENSG00000180957 ENSG00000035115 ENSG00000165929 ENSG00000105193 ENSG00000119801 ENSG00000197756 ENSG00000062650 ENSG00000067167 ENSG00000122958 ENSG00000198851 ENSG00000175582 ENSG00000100201 ENSG00000170571 ENSG00000147443 ENSG00000205981 ENSG00000184863 ENSG00000181924 ENSG00000100883 ENSG00000185658 ENSG00000147274 ENSG00000124422 ENSG00000083312 ENSG00000179912 ENSG00000112146 ENSG00000169180 ENSG00000072501 ENSG00000141580 ENSG00000013374 ENSG00000034677 ENSG00000117298 ENSG00000090905 ENSG00000133858 ENSG00000060237 ENSG00000253719 ENSG00000167258 ENSG00000168807 ENSG00000188641 ENSG00000116898 ENSG00000009954 ENSG00000096384 ENSG00000168438 ENSG00000179950 ENSG00000182568 ENSG00000023318 ENSG00000180398 ENSG00000172115 ENSG00000111670 ENSG00000114850 ENSG00000064012 ENSG00000187764 ENSG00000108107 ENSG00000090006 ENSG00000167522 ENSG00000126945 ENSG00000168137 ENSG00000164022 ENSG00000151461 ENSG00000157514 ENSG00000224877 ENSG00000198899 ENSG00000102401 ENSG00000265241 ENSG00000186834 ENSG00000065243 ENSG00000100592 ENSG00000188483 ENSG00000082898 ENSG00000101421 ENSG00000177600 ENSG00000009307 ENSG00000081019 ENSG00000187840 ENSG00000143153 ENSG00000110876 ENSG00000163644 ENSG00000163939 ENSG00000136942 ENSG00000156804 ENSG00000104164 ENSG00000092531 ENSG00000130522 ENSG00000158050 ENSG00000160209 ENSG00000126005 ENSG00000197958 ENSG00000087074 ENSG00000134825 ENSG00000068912 ENSG00000187514 ENSG00000106355 ENSG00000183617 ENSG00000116824 ENSG00000180448 ENSG00000112697 ENSG00000166295 ENSG00000143384 ENSG00000122026 ENSG00000128590 ENSG00000026508 ENSG00000162923 ENSG00000138688 ENSG00000213741 ENSG00000182934 ENSG00000114956 ENSG00000144674 ENSG00000169057 ENSG00000210196 ENSG00000130520 ENSG00000189241 ENSG00000102189 ENSG00000170345 ENSG00000130414 ENSG00000079950 ENSG00000172922 ENSG00000275302 ENSG00000112406 ENSG00000119950 ENSG00000100380 ENSG00000198840 ENSG00000145592 ENSG00000111615 ENSG00000109475 ENSG00000114353 ENSG00000147403 ENSG00000132002 ENSG00000079332 ENSG00000153774 ENSG00000123240 ENSG00000109929 ENSG00000198727 ENSG00000186468 ENSG00000117500 ENSG00000257103 ENSG00000206573 ENSG00000069345 ENSG00000162244 ENSG00000067048 ENSG00000160593 ENSG00000229117 ENSG00000163320 ENSG00000173120 ENSG00000143727 ENSG00000076641 ENSG00000198712 ENSG00000091164 ENSG00000100221 ENSG00000138166 ENSG00000137309 ENSG00000114861 ENSG00000069493 ENSG00000156482 ENSG00000127184 ENSG00000162616 ENSG00000185129 ENSG00000062716 ENSG00000101361 ENSG00000118181 ENSG00000105640 ENSG00000205581 ENSG00000100796 ENSG00000163605 ENSG00000140988 ENSG00000129534 ENSG00000100503 ENSG00000119541 ENSG00000116209 ENSG00000145860 ENSG00000169826 ENSG00000177565 ENSG00000204435 ENSG00000102760 ENSG00000111666 ENSG00000140740 ENSG00000077380 ENSG00000142546 ENSG00000050405 ENSG00000137076 ENSG00000108055 ENSG00000159352 ENSG00000156256 ENSG00000154473 ENSG00000117410 ENSG00000173020 ENSG00000198918 ENSG00000115241 ENSG00000143774 ENSG00000149187 ENSG00000206560 ENSG00000173110 ENSG00000129351 ENSG00000112306 ENSG00000072274 ENSG00000168685 ENSG00000181467 ENSG00000117523 ENSG00000143799 ENSG00000118058 ENSG00000132424 ENSG00000126777 ENSG00000156976 ENSG00000120686 ENSG00000138279 ENSG00000222041 ENSG00000134453 ENSG00000170275 ENSG00000170860 ENSG00000134419 ENSG00000184990 ENSG00000111885 ENSG00000099901 ENSG00000076928 ENSG00000145734 ENSG00000137312 ENSG00000142541 ENSG00000128699 ENSG00000177189 ENSG00000109920 ENSG00000096060 ENSG00000138674 ENSG00000113282 ENSG00000186591 ENSG00000128534 ENSG00000198189 ENSG00000150991 ENSG00000231500 ENSG00000187051 ENSG00000131236 ENSG00000143158 ENSG00000165672 ENSG00000205302 ENSG00000172183 ENSG00000178980 ENSG00000134352 ENSG00000122417 ENSG00000182004 ENSG00000169967 ENSG00000171681 ENSG00000163714 ENSG00000072778 ENSG00000205531 ENSG00000114416 ENSG00000135624 ENSG00000163902 ENSG00000071054 ENSG00000178449 ENSG00000077147 ENSG00000124942 ENSG00000170776 ENSG00000187735 ENSG00000159023 ENSG00000087460 ENSG00000090621 ENSG00000133872 ENSG00000072364 ENSG00000073614 ENSG00000198625 ENSG00000105379 ENSG00000204628 ENSG00000104131 ENSG00000105323 ENSG00000134046 ENSG00000111640 ENSG00000083845 ENSG00000084733 ENSG00000122566 ENSG00000108774 ENSG00000138085 ENSG00000065054 ENSG00000169926 ENSG00000245532 ENSG00000221983 ENSG00000198034 ENSG00000089327 ENSG00000182899 ENSG00000141867 ENSG00000166595 ENSG00000114439 ENSG00000198856 ENSG00000135837 ENSG00000133639 ENSG00000087191 ENSG00000088930 ENSG00000065413 ENSG00000140319 ENSG00000116350 ENSG00000146278 ENSG00000083896 ENSG00000171862 ENSG00000131143 ENSG00000172809 ENSG00000213719 ENSG00000127884 ENSG00000041357 ENSG00000171222 ENSG00000116539 ENSG00000215845 ENSG00000163956 ENSG00000131370 ENSG00000114331 ENSG00000167468 ENSG00000111276 ENSG00000143543 ENSG00000177954 ENSG00000084754 ENSG00000105968 ENSG00000124172 ENSG00000266472 ENSG00000087365 ENSG00000160213 ENSG00000005893 ENSG00000143933 ENSG00000177697 ENSG00000161011 ENSG00000110367 ENSG00000096746 ENSG00000085662 ENSG00000164190 ENSG00000130332 ENSG00000198355 ENSG00000112378 ENSG00000145425 ENSG00000211450 ENSG00000137776 ENSG00000136819 ENSG00000078674 ENSG00000116171 ENSG00000111371 ENSG00000196683 ENSG00000029363 ENSG00000260032 ENSG00000125534 ENSG00000150867 ENSG00000146425 ENSG00000166441 ENSG00000115128 ENSG00000171863 ENSG00000171858 ENSG00000067064 ENSG00000120963 ENSG00000172757 ENSG00000105401 ENSG00000155366 ENSG00000147684 ENSG00000108256 ENSG00000184203 ENSG00000173559 ENSG00000099341 ENSG00000142676 ENSG00000114978 ENSG00000115677 ENSG00000163682 ENSG00000008988 ENSG00000214253 ENSG00000233927 ENSG00000104388 ENSG00000120533 ENSG00000172428 ENSG00000149273 ENSG00000164754 ENSG00000198604 ENSG00000117335 ENSG00000090060 ENSG00000185043 ENSG00000054148 ENSG00000135842 ENSG00000122034 ENSG00000105939 ENSG00000164463 ENSG00000044574 ENSG00000173762 ENSG00000111897 ENSG00000105669 ENSG00000166848 ENSG00000138767 ENSG00000138495 ENSG00000143947 ENSG00000197061 ENSG00000113580 ENSG00000155957 ENSG00000173113 ENSG00000092841 ENSG00000188846 ENSG00000118418 ENSG00000196352 ENSG00000087086 ENSG00000134248 ENSG00000125835 ENSG00000152558 ENSG00000135048 ENSG00000137876 ENSG00000047410 ENSG00000125977 ENSG00000169764 ENSG00000105329 ENSG00000246705 ENSG00000148303 ENSG00000091039 ENSG00000034713 ENSG00000213145 ENSG00000142937 ENSG00000070081 ENSG00000180370 ENSG00000151929 ENSG00000196531 ENSG00000102007 ENSG00000187239 ENSG00000126524 ENSG00000138668 ENSG00000004799 ENSG00000183172 ENSG00000118363 ENSG00000101608 ENSG00000111011 ENSG00000177885 ENSG00000135535 ENSG00000013441 ENSG00000120129 ENSG00000164442 ENSG00000119707 ENSG00000173674 ENSG00000107738 ENSG00000173726 ENSG00000115524 ENSG00000171988 ENSG00000177606 ENSG00000135968 ENSG00000171530 ENSG00000170889 ENSG00000084070 ENSG00000265681 ENSG00000067900 ENSG00000133226 ENSG00000163584 ENSG00000120306 ENSG00000139218 ENSG00000104660 ENSG00000105404 ENSG00000091527 ENSG00000100316 ENSG00000174748 ENSG00000085224 ENSG00000244879 ENSG00000104765 ENSG00000156675 ENSG00000136156 ENSG00000144713 ENSG00000198886 ENSG00000136167 ENSG00000005483 ENSG00000110958 ENSG00000168610 ENSG00000078596 ENSG00000205542 ENSG00000150593 ENSG00000112335 ENSG00000180817 ENSG00000147526 ENSG00000008952 ENSG00000184007 ENSG00000092010 ENSG00000127022 ENSG00000115268 ENSG00000169045 ENSG00000161547 ENSG00000165119 ENSG00000141232 ENSG00000138326 ENSG00000010810 ENSG00000110321 ENSG00000120690 ENSG00000060138 ENSG00000244754 ENSG00000140941 ENSG00000161016 ENSG00000124614 ENSG00000108953 ENSG00000269893 ENSG00000089737 ENSG00000188612 ENSG00000142156 ENSG00000113558 ENSG00000034510 ENSG00000228474 ENSG00000234745 ENSG00000183283 ENSG00000099624 ENSG00000142864 ENSG00000159140 ENSG00000179820 ENSG00000185624 ENSG00000198786 ENSG00000130592 ENSG00000134884 ENSG00000116560 ENSG00000144746 ENSG00000142168 ENSG00000231721 ENSG00000162434 ENSG00000198242 ENSG00000178982 ENSG00000069275 ENSG00000111341 ENSG00000198755 ENSG00000173915 ENSG00000104408 ENSG00000248527 ENSG00000110955 ENSG00000119335 ENSG00000131051 ENSG00000164405 ENSG00000155307 ENSG00000131174 ENSG00000121966 ENSG00000078304 ENSG00000180353 ENSG00000163565 ENSG00000075415 ENSG00000168653 ENSG00000197956 ENSG00000206503 ENSG00000118816 ENSG00000137154 ENSG00000267519 ENSG00000188229 ENSG00000110700 ENSG00000166913 ENSG00000111678 ENSG00000026025 ENSG00000198763 ENSG00000164919 ENSG00000115165 ENSG00000152601 ENSG00000163399 ENSG00000147065 ENSG00000003402 ENSG00000128340 ENSG00000117091 ENSG00000171223 ENSG00000150093 ENSG00000167996 ENSG00000108298 ENSG00000189403 ENSG00000081320 ENSG00000245910 ENSG00000215301 ENSG00000153187 ENSG00000174718 ENSG00000187109 ENSG00000123349 ENSG00000111716 ENSG00000081237 ENSG00000198888 ENSG00000145741 ENSG00000105373 ENSG00000115053 ENSG00000104529 ENSG00000142227 ENSG00000155368 ENSG00000153234 ENSG00000163660 ENSG00000143549 ENSG00000177410 ENSG00000124107 ENSG00000188042 ENSG00000134954 ENSG00000167658 ENSG00000265972 ENSG00000129824 ENSG00000147872 ENSG00000167552 ENSG00000104904 ENSG00000115541 ENSG00000111229 ENSG00000100097 ENSG00000120694 ENSG00000127528 ENSG00000152518 ENSG00000170315 ENSG00000163041 ENSG00000144802 ENSG00000234741 ENSG00000092820 ENSG00000198668 ENSG00000071082 ENSG00000117450 ENSG00000122862 ENSG00000166598 ENSG00000149806 ENSG00000010278 ENSG00000125868 ENSG00000108518 ENSG00000135821 ENSG00000125691 ENSG00000212907 ENSG00000114942 ENSG00000160888 ENSG00000172216 ENSG00000122406 ENSG00000168028 ENSG00000142669 ENSG00000204525 ENSG00000130255 ENSG00000089157 ENSG00000185650 ENSG00000169442 ENSG00000063177 ENSG00000187193 ENSG00000161970 ENSG00000135404 ENSG00000182718 ENSG00000118503 ENSG00000105372 ENSG00000197747 ENSG00000110848 ENSG00000185201 ENSG00000112096 ENSG00000221869 ENSG00000130066 ENSG00000163191 ENSG00000143546 ENSG00000101443 ENSG00000109205 ENSG00000011465 ENSG00000169908',\n",
       " 'cell_type': 'CD8-positive, alpha-beta T cell'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4323cd6eced48d183a1584596747386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/458994 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\johnz\\anaconda3\\envs\\celldl\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3586: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e026e555c44457b82b5085baa60c54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/24158 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(preprocess_data,batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29d9794d98e6457ea082b7cf97b984f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/459 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20949452142"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['train'].to_json(\"../data/TabulaSapiens_tokenized_dataset_train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b376a7d110e747e0910e52e0f30788c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1100173743"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['test'].to_json(\"../data/TabulaSapiens_tokenized_dataset_test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (C:/Users/johnz/.cache/huggingface/datasets/json/default-3fcedefba4e19bbd/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deabe4b3039940ab8a3d3b7905563f34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = load_dataset('json', data_files={'train': '../data/TabulaSapiens_tokenized_dataset_train.json','test': '../data/TabulaSapiens_tokenized_dataset_test.json'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('data/tokenized_datasets.pkl', 'wb') as f:\n",
    "#    pickle.dump(tokenized_datasets, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenized_datasets = pickle.load(open('data/tokenized_datasets.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir='t5',\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=10000,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=200,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=10000,\n",
    "    learning_rate=4e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=1,\n",
    "    predict_with_generate=True,\n",
    "    fp16=False,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"rouge1\",\n",
    "    report_to=\"tensorboard\"\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer)\n",
    "metric = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    \n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip()))\n",
    "                      for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) \n",
    "                      for label in decoded_labels]\n",
    "    \n",
    "    # Compute ROUGE scores\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels,\n",
    "                            use_stemmer=True)\n",
    "\n",
    "    # Extract ROUGE f1 scores\n",
    "    result = {key: value * 100 for key, value in result.items()}\n",
    "    \n",
    "    # Add mean generated length to metrics\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id)\n",
    "                      for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    \n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return AutoModelForSeq2SeqLM.from_pretrained('t5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model_init=model_init,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\johnz\\anaconda3\\envs\\celldl\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcebb258257247dcbaa17ad9589921a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114749 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0963, 'learning_rate': 3.993028261684198e-05, 'epoch': 0.0}\n",
      "{'loss': 0.3335, 'learning_rate': 3.9860565233683956e-05, 'epoch': 0.0}\n",
      "{'loss': 0.2864, 'learning_rate': 3.9790847850525935e-05, 'epoch': 0.01}\n",
      "{'loss': 0.2502, 'learning_rate': 3.972113046736791e-05, 'epoch': 0.01}\n",
      "{'loss': 0.2309, 'learning_rate': 3.965141308420989e-05, 'epoch': 0.01}\n",
      "{'loss': 0.2322, 'learning_rate': 3.958169570105186e-05, 'epoch': 0.01}\n",
      "{'loss': 0.2238, 'learning_rate': 3.951197831789384e-05, 'epoch': 0.01}\n",
      "{'loss': 0.218, 'learning_rate': 3.944226093473581e-05, 'epoch': 0.01}\n",
      "{'loss': 0.2166, 'learning_rate': 3.937254355157779e-05, 'epoch': 0.02}\n",
      "{'loss': 0.2141, 'learning_rate': 3.930282616841977e-05, 'epoch': 0.02}\n",
      "{'loss': 0.2129, 'learning_rate': 3.9233108785261746e-05, 'epoch': 0.02}\n",
      "{'loss': 0.2083, 'learning_rate': 3.9163391402103725e-05, 'epoch': 0.02}\n",
      "{'loss': 0.2008, 'learning_rate': 3.9093674018945705e-05, 'epoch': 0.02}\n",
      "{'loss': 0.1987, 'learning_rate': 3.902395663578768e-05, 'epoch': 0.02}\n",
      "{'loss': 0.1925, 'learning_rate': 3.895423925262966e-05, 'epoch': 0.03}\n",
      "{'loss': 0.1874, 'learning_rate': 3.888452186947164e-05, 'epoch': 0.03}\n",
      "{'loss': 0.1927, 'learning_rate': 3.881480448631361e-05, 'epoch': 0.03}\n",
      "{'loss': 0.1898, 'learning_rate': 3.874508710315559e-05, 'epoch': 0.03}\n",
      "{'loss': 0.188, 'learning_rate': 3.867536971999756e-05, 'epoch': 0.03}\n",
      "{'loss': 0.1828, 'learning_rate': 3.860565233683954e-05, 'epoch': 0.03}\n",
      "{'loss': 0.1779, 'learning_rate': 3.8535934953681515e-05, 'epoch': 0.04}\n",
      "{'loss': 0.1757, 'learning_rate': 3.8466217570523495e-05, 'epoch': 0.04}\n",
      "{'loss': 0.1759, 'learning_rate': 3.839650018736547e-05, 'epoch': 0.04}\n",
      "{'loss': 0.1761, 'learning_rate': 3.832678280420745e-05, 'epoch': 0.04}\n",
      "{'loss': 0.1747, 'learning_rate': 3.825706542104943e-05, 'epoch': 0.04}\n",
      "{'loss': 0.175, 'learning_rate': 3.81873480378914e-05, 'epoch': 0.05}\n",
      "{'loss': 0.1721, 'learning_rate': 3.811763065473338e-05, 'epoch': 0.05}\n",
      "{'loss': 0.1701, 'learning_rate': 3.804791327157535e-05, 'epoch': 0.05}\n",
      "{'loss': 0.1672, 'learning_rate': 3.797819588841733e-05, 'epoch': 0.05}\n",
      "{'loss': 0.1708, 'learning_rate': 3.7908478505259305e-05, 'epoch': 0.05}\n",
      "{'loss': 0.1708, 'learning_rate': 3.7838761122101284e-05, 'epoch': 0.05}\n",
      "{'loss': 0.1633, 'learning_rate': 3.7769043738943264e-05, 'epoch': 0.06}\n",
      "{'loss': 0.1655, 'learning_rate': 3.769932635578524e-05, 'epoch': 0.06}\n",
      "{'loss': 0.1606, 'learning_rate': 3.7629608972627216e-05, 'epoch': 0.06}\n",
      "{'loss': 0.1605, 'learning_rate': 3.755989158946919e-05, 'epoch': 0.06}\n",
      "{'loss': 0.1654, 'learning_rate': 3.749017420631117e-05, 'epoch': 0.06}\n",
      "{'loss': 0.1614, 'learning_rate': 3.742045682315314e-05, 'epoch': 0.06}\n",
      "{'loss': 0.162, 'learning_rate': 3.735073943999512e-05, 'epoch': 0.07}\n",
      "{'loss': 0.1579, 'learning_rate': 3.72810220568371e-05, 'epoch': 0.07}\n",
      "{'loss': 0.1613, 'learning_rate': 3.721130467367908e-05, 'epoch': 0.07}\n",
      "{'loss': 0.1558, 'learning_rate': 3.7141587290521054e-05, 'epoch': 0.07}\n",
      "{'loss': 0.1553, 'learning_rate': 3.707186990736303e-05, 'epoch': 0.07}\n",
      "{'loss': 0.1543, 'learning_rate': 3.7002152524205006e-05, 'epoch': 0.07}\n",
      "{'loss': 0.152, 'learning_rate': 3.6932435141046986e-05, 'epoch': 0.08}\n",
      "{'loss': 0.1582, 'learning_rate': 3.686271775788896e-05, 'epoch': 0.08}\n",
      "{'loss': 0.1613, 'learning_rate': 3.679300037473094e-05, 'epoch': 0.08}\n",
      "{'loss': 0.1595, 'learning_rate': 3.672328299157292e-05, 'epoch': 0.08}\n",
      "{'loss': 0.1493, 'learning_rate': 3.665356560841489e-05, 'epoch': 0.08}\n",
      "{'loss': 0.157, 'learning_rate': 3.658384822525687e-05, 'epoch': 0.09}\n",
      "{'loss': 0.1482, 'learning_rate': 3.6514130842098843e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b90ce372d15347a4a952c7ad7716ebd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.13371586799621582, 'eval_rouge1': 36.4161, 'eval_rouge2': 16.2527, 'eval_rougeL': 36.3695, 'eval_rougeLsum': 36.3868, 'eval_gen_len': 6.4897, 'eval_runtime': 2524.8417, 'eval_samples_per_second': 9.568, 'eval_steps_per_second': 2.392, 'epoch': 0.09}\n",
      "{'loss': 0.1468, 'learning_rate': 3.644441345894082e-05, 'epoch': 0.09}\n",
      "{'loss': 0.1461, 'learning_rate': 3.6374696075782796e-05, 'epoch': 0.09}\n",
      "{'loss': 0.1476, 'learning_rate': 3.6304978692624776e-05, 'epoch': 0.09}\n",
      "{'loss': 0.142, 'learning_rate': 3.623526130946675e-05, 'epoch': 0.09}\n",
      "{'loss': 0.1464, 'learning_rate': 3.616554392630873e-05, 'epoch': 0.1}\n",
      "{'loss': 0.1423, 'learning_rate': 3.609582654315071e-05, 'epoch': 0.1}\n",
      "{'loss': 0.1511, 'learning_rate': 3.602610915999268e-05, 'epoch': 0.1}\n",
      "{'loss': 0.1424, 'learning_rate': 3.595639177683466e-05, 'epoch': 0.1}\n",
      "{'loss': 0.1453, 'learning_rate': 3.588667439367663e-05, 'epoch': 0.1}\n",
      "{'loss': 0.1389, 'learning_rate': 3.581695701051861e-05, 'epoch': 0.1}\n",
      "{'loss': 0.1381, 'learning_rate': 3.5747239627360586e-05, 'epoch': 0.11}\n",
      "{'loss': 0.137, 'learning_rate': 3.5677522244202565e-05, 'epoch': 0.11}\n",
      "{'loss': 0.1397, 'learning_rate': 3.560780486104454e-05, 'epoch': 0.11}\n",
      "{'loss': 0.1387, 'learning_rate': 3.5538087477886525e-05, 'epoch': 0.11}\n",
      "{'loss': 0.1335, 'learning_rate': 3.54683700947285e-05, 'epoch': 0.11}\n",
      "{'loss': 0.1354, 'learning_rate': 3.539865271157048e-05, 'epoch': 0.12}\n",
      "{'loss': 0.1264, 'learning_rate': 3.532893532841245e-05, 'epoch': 0.12}\n",
      "{'loss': 0.135, 'learning_rate': 3.525921794525443e-05, 'epoch': 0.12}\n",
      "{'loss': 0.1333, 'learning_rate': 3.51895005620964e-05, 'epoch': 0.12}\n",
      "{'loss': 0.1339, 'learning_rate': 3.511978317893838e-05, 'epoch': 0.12}\n",
      "{'loss': 0.1333, 'learning_rate': 3.505006579578036e-05, 'epoch': 0.12}\n",
      "{'loss': 0.1259, 'learning_rate': 3.4980348412622335e-05, 'epoch': 0.13}\n",
      "{'loss': 0.1261, 'learning_rate': 3.4910631029464314e-05, 'epoch': 0.13}\n",
      "{'loss': 0.1281, 'learning_rate': 3.484091364630629e-05, 'epoch': 0.13}\n",
      "{'loss': 0.1239, 'learning_rate': 3.477119626314827e-05, 'epoch': 0.13}\n",
      "{'loss': 0.1211, 'learning_rate': 3.470147887999024e-05, 'epoch': 0.13}\n",
      "{'loss': 0.1195, 'learning_rate': 3.463176149683222e-05, 'epoch': 0.13}\n",
      "{'loss': 0.1178, 'learning_rate': 3.45620441136742e-05, 'epoch': 0.14}\n",
      "{'loss': 0.1271, 'learning_rate': 3.449232673051617e-05, 'epoch': 0.14}\n",
      "{'loss': 0.1245, 'learning_rate': 3.442260934735815e-05, 'epoch': 0.14}\n",
      "{'loss': 0.1194, 'learning_rate': 3.4352891964200125e-05, 'epoch': 0.14}\n",
      "{'loss': 0.124, 'learning_rate': 3.4283174581042104e-05, 'epoch': 0.14}\n",
      "{'loss': 0.1178, 'learning_rate': 3.421345719788408e-05, 'epoch': 0.14}\n",
      "{'loss': 0.1114, 'learning_rate': 3.414373981472606e-05, 'epoch': 0.15}\n",
      "{'loss': 0.1173, 'learning_rate': 3.407402243156803e-05, 'epoch': 0.15}\n",
      "{'loss': 0.1231, 'learning_rate': 3.400430504841001e-05, 'epoch': 0.15}\n",
      "{'loss': 0.1198, 'learning_rate': 3.393458766525199e-05, 'epoch': 0.15}\n",
      "{'loss': 0.1163, 'learning_rate': 3.386487028209396e-05, 'epoch': 0.15}\n",
      "{'loss': 0.1152, 'learning_rate': 3.379515289893594e-05, 'epoch': 0.16}\n",
      "{'loss': 0.1191, 'learning_rate': 3.372543551577792e-05, 'epoch': 0.16}\n",
      "{'loss': 0.1129, 'learning_rate': 3.3655718132619894e-05, 'epoch': 0.16}\n",
      "{'loss': 0.1103, 'learning_rate': 3.3586000749461874e-05, 'epoch': 0.16}\n",
      "{'loss': 0.1161, 'learning_rate': 3.351628336630385e-05, 'epoch': 0.16}\n",
      "{'loss': 0.1215, 'learning_rate': 3.3446565983145826e-05, 'epoch': 0.16}\n",
      "{'loss': 0.1146, 'learning_rate': 3.3376848599987806e-05, 'epoch': 0.17}\n",
      "{'loss': 0.1119, 'learning_rate': 3.330713121682978e-05, 'epoch': 0.17}\n",
      "{'loss': 0.1129, 'learning_rate': 3.323741383367176e-05, 'epoch': 0.17}\n",
      "{'loss': 0.1161, 'learning_rate': 3.316769645051373e-05, 'epoch': 0.17}\n",
      "{'loss': 0.1092, 'learning_rate': 3.309797906735571e-05, 'epoch': 0.17}\n",
      "{'loss': 0.1134, 'learning_rate': 3.3028261684197684e-05, 'epoch': 0.17}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a53e1e425734e4bb025ea7c4509c23d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09621623903512955, 'eval_rouge1': 60.7263, 'eval_rouge2': 33.8883, 'eval_rougeL': 60.7143, 'eval_rougeLsum': 60.7063, 'eval_gen_len': 6.5735, 'eval_runtime': 2533.5744, 'eval_samples_per_second': 9.535, 'eval_steps_per_second': 2.384, 'epoch': 0.17}\n",
      "{'loss': 0.1043, 'learning_rate': 3.295854430103966e-05, 'epoch': 0.18}\n",
      "{'loss': 0.1112, 'learning_rate': 3.288882691788164e-05, 'epoch': 0.18}\n",
      "{'loss': 0.1087, 'learning_rate': 3.2819109534723616e-05, 'epoch': 0.18}\n",
      "{'loss': 0.1117, 'learning_rate': 3.2749392151565595e-05, 'epoch': 0.18}\n",
      "{'loss': 0.1095, 'learning_rate': 3.267967476840757e-05, 'epoch': 0.18}\n",
      "{'loss': 0.1084, 'learning_rate': 3.260995738524955e-05, 'epoch': 0.18}\n",
      "{'loss': 0.1044, 'learning_rate': 3.254024000209152e-05, 'epoch': 0.19}\n",
      "{'loss': 0.1103, 'learning_rate': 3.24705226189335e-05, 'epoch': 0.19}\n",
      "{'loss': 0.1035, 'learning_rate': 3.2400805235775473e-05, 'epoch': 0.19}\n",
      "{'loss': 0.1026, 'learning_rate': 3.233108785261745e-05, 'epoch': 0.19}\n",
      "{'loss': 0.1041, 'learning_rate': 3.226137046945943e-05, 'epoch': 0.19}\n",
      "{'loss': 0.1072, 'learning_rate': 3.2191653086301406e-05, 'epoch': 0.2}\n",
      "{'loss': 0.1052, 'learning_rate': 3.2121935703143385e-05, 'epoch': 0.2}\n",
      "{'loss': 0.1052, 'learning_rate': 3.205221831998536e-05, 'epoch': 0.2}\n",
      "{'loss': 0.1057, 'learning_rate': 3.198250093682734e-05, 'epoch': 0.2}\n",
      "{'loss': 0.1049, 'learning_rate': 3.191278355366932e-05, 'epoch': 0.2}\n",
      "{'loss': 0.1041, 'learning_rate': 3.18430661705113e-05, 'epoch': 0.2}\n",
      "{'loss': 0.1031, 'learning_rate': 3.177334878735327e-05, 'epoch': 0.21}\n",
      "{'loss': 0.0993, 'learning_rate': 3.170363140419525e-05, 'epoch': 0.21}\n",
      "{'loss': 0.0978, 'learning_rate': 3.163391402103722e-05, 'epoch': 0.21}\n",
      "{'loss': 0.1069, 'learning_rate': 3.15641966378792e-05, 'epoch': 0.21}\n",
      "{'loss': 0.0989, 'learning_rate': 3.1494479254721175e-05, 'epoch': 0.21}\n",
      "{'loss': 0.1005, 'learning_rate': 3.1424761871563155e-05, 'epoch': 0.21}\n",
      "{'loss': 0.0984, 'learning_rate': 3.135504448840513e-05, 'epoch': 0.22}\n",
      "{'loss': 0.1044, 'learning_rate': 3.128532710524711e-05, 'epoch': 0.22}\n",
      "{'loss': 0.0943, 'learning_rate': 3.121560972208909e-05, 'epoch': 0.22}\n",
      "{'loss': 0.0969, 'learning_rate': 3.114589233893106e-05, 'epoch': 0.22}\n",
      "{'loss': 0.1, 'learning_rate': 3.107617495577304e-05, 'epoch': 0.22}\n",
      "{'loss': 0.1027, 'learning_rate': 3.100645757261501e-05, 'epoch': 0.22}\n",
      "{'loss': 0.0986, 'learning_rate': 3.093674018945699e-05, 'epoch': 0.23}\n",
      "{'loss': 0.0936, 'learning_rate': 3.0867022806298965e-05, 'epoch': 0.23}\n",
      "{'loss': 0.1015, 'learning_rate': 3.0797305423140944e-05, 'epoch': 0.23}\n",
      "{'loss': 0.1013, 'learning_rate': 3.0727588039982924e-05, 'epoch': 0.23}\n",
      "{'loss': 0.0957, 'learning_rate': 3.06578706568249e-05, 'epoch': 0.23}\n",
      "{'loss': 0.1029, 'learning_rate': 3.0588153273666877e-05, 'epoch': 0.24}\n",
      "{'loss': 0.0945, 'learning_rate': 3.051843589050885e-05, 'epoch': 0.24}\n",
      "{'loss': 0.0946, 'learning_rate': 3.0448718507350826e-05, 'epoch': 0.24}\n",
      "{'loss': 0.0883, 'learning_rate': 3.0379001124192805e-05, 'epoch': 0.24}\n",
      "{'loss': 0.0957, 'learning_rate': 3.030928374103478e-05, 'epoch': 0.24}\n",
      "{'loss': 0.0964, 'learning_rate': 3.023956635787676e-05, 'epoch': 0.24}\n",
      "{'loss': 0.0991, 'learning_rate': 3.0169848974718737e-05, 'epoch': 0.25}\n",
      "{'loss': 0.0927, 'learning_rate': 3.0100131591560714e-05, 'epoch': 0.25}\n",
      "{'loss': 0.093, 'learning_rate': 3.0030414208402693e-05, 'epoch': 0.25}\n",
      "{'loss': 0.0897, 'learning_rate': 2.996069682524467e-05, 'epoch': 0.25}\n",
      "{'loss': 0.0925, 'learning_rate': 2.9890979442086646e-05, 'epoch': 0.25}\n",
      "{'loss': 0.0911, 'learning_rate': 2.9821262058928622e-05, 'epoch': 0.25}\n",
      "{'loss': 0.0894, 'learning_rate': 2.97515446757706e-05, 'epoch': 0.26}\n",
      "{'loss': 0.0925, 'learning_rate': 2.9681827292612575e-05, 'epoch': 0.26}\n",
      "{'loss': 0.0996, 'learning_rate': 2.961210990945455e-05, 'epoch': 0.26}\n",
      "{'loss': 0.0887, 'learning_rate': 2.9542392526296527e-05, 'epoch': 0.26}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10aab872f5674eb6891cee2c603509cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08196986466646194, 'eval_rouge1': 68.9709, 'eval_rouge2': 41.5447, 'eval_rougeL': 68.9566, 'eval_rougeLsum': 68.9287, 'eval_gen_len': 7.05, 'eval_runtime': 2449.0393, 'eval_samples_per_second': 9.864, 'eval_steps_per_second': 2.466, 'epoch': 0.26}\n",
      "{'loss': 0.0942, 'learning_rate': 2.9472675143138503e-05, 'epoch': 0.26}\n",
      "{'loss': 0.0924, 'learning_rate': 2.9402957759980483e-05, 'epoch': 0.26}\n",
      "{'loss': 0.0914, 'learning_rate': 2.933324037682246e-05, 'epoch': 0.27}\n",
      "{'loss': 0.0936, 'learning_rate': 2.9263522993664436e-05, 'epoch': 0.27}\n",
      "{'loss': 0.0891, 'learning_rate': 2.9193805610506412e-05, 'epoch': 0.27}\n",
      "{'loss': 0.0888, 'learning_rate': 2.9124088227348388e-05, 'epoch': 0.27}\n",
      "{'loss': 0.091, 'learning_rate': 2.9054370844190364e-05, 'epoch': 0.27}\n",
      "{'loss': 0.0889, 'learning_rate': 2.898465346103234e-05, 'epoch': 0.28}\n",
      "{'loss': 0.0888, 'learning_rate': 2.8914936077874317e-05, 'epoch': 0.28}\n",
      "{'loss': 0.093, 'learning_rate': 2.8845218694716293e-05, 'epoch': 0.28}\n",
      "{'loss': 0.091, 'learning_rate': 2.8775501311558273e-05, 'epoch': 0.28}\n",
      "{'loss': 0.0834, 'learning_rate': 2.870578392840025e-05, 'epoch': 0.28}\n",
      "{'loss': 0.0865, 'learning_rate': 2.8636066545242225e-05, 'epoch': 0.28}\n",
      "{'loss': 0.0885, 'learning_rate': 2.85663491620842e-05, 'epoch': 0.29}\n",
      "{'loss': 0.0833, 'learning_rate': 2.8496631778926178e-05, 'epoch': 0.29}\n",
      "{'loss': 0.0817, 'learning_rate': 2.8426914395768158e-05, 'epoch': 0.29}\n",
      "{'loss': 0.0848, 'learning_rate': 2.8357197012610137e-05, 'epoch': 0.29}\n",
      "{'loss': 0.091, 'learning_rate': 2.8287479629452113e-05, 'epoch': 0.29}\n",
      "{'loss': 0.0896, 'learning_rate': 2.821776224629409e-05, 'epoch': 0.29}\n",
      "{'loss': 0.0871, 'learning_rate': 2.8148044863136066e-05, 'epoch': 0.3}\n",
      "{'loss': 0.0881, 'learning_rate': 2.8078327479978042e-05, 'epoch': 0.3}\n",
      "{'loss': 0.0864, 'learning_rate': 2.800861009682002e-05, 'epoch': 0.3}\n",
      "{'loss': 0.0886, 'learning_rate': 2.7938892713661995e-05, 'epoch': 0.3}\n",
      "{'loss': 0.0789, 'learning_rate': 2.786917533050397e-05, 'epoch': 0.3}\n",
      "{'loss': 0.0847, 'learning_rate': 2.779945794734595e-05, 'epoch': 0.31}\n",
      "{'loss': 0.0851, 'learning_rate': 2.7729740564187927e-05, 'epoch': 0.31}\n",
      "{'loss': 0.0829, 'learning_rate': 2.7660023181029903e-05, 'epoch': 0.31}\n",
      "{'loss': 0.0915, 'learning_rate': 2.759030579787188e-05, 'epoch': 0.31}\n",
      "{'loss': 0.086, 'learning_rate': 2.7520588414713856e-05, 'epoch': 0.31}\n",
      "{'loss': 0.0857, 'learning_rate': 2.7450871031555832e-05, 'epoch': 0.31}\n",
      "{'loss': 0.0807, 'learning_rate': 2.7381153648397808e-05, 'epoch': 0.32}\n",
      "{'loss': 0.0845, 'learning_rate': 2.7311436265239785e-05, 'epoch': 0.32}\n",
      "{'loss': 0.0855, 'learning_rate': 2.724171888208176e-05, 'epoch': 0.32}\n",
      "{'loss': 0.0758, 'learning_rate': 2.717200149892374e-05, 'epoch': 0.32}\n",
      "{'loss': 0.0845, 'learning_rate': 2.7102284115765717e-05, 'epoch': 0.32}\n",
      "{'loss': 0.0795, 'learning_rate': 2.7032566732607693e-05, 'epoch': 0.32}\n",
      "{'loss': 0.088, 'learning_rate': 2.696284934944967e-05, 'epoch': 0.33}\n",
      "{'loss': 0.0803, 'learning_rate': 2.6893131966291645e-05, 'epoch': 0.33}\n",
      "{'loss': 0.0814, 'learning_rate': 2.6823414583133622e-05, 'epoch': 0.33}\n",
      "{'loss': 0.0854, 'learning_rate': 2.6753697199975598e-05, 'epoch': 0.33}\n",
      "{'loss': 0.0826, 'learning_rate': 2.668397981681758e-05, 'epoch': 0.33}\n",
      "{'loss': 0.0801, 'learning_rate': 2.6614262433659557e-05, 'epoch': 0.33}\n",
      "{'loss': 0.0807, 'learning_rate': 2.6544545050501534e-05, 'epoch': 0.34}\n",
      "{'loss': 0.0845, 'learning_rate': 2.647482766734351e-05, 'epoch': 0.34}\n",
      "{'loss': 0.0848, 'learning_rate': 2.6405110284185486e-05, 'epoch': 0.34}\n",
      "{'loss': 0.0808, 'learning_rate': 2.6335392901027462e-05, 'epoch': 0.34}\n",
      "{'loss': 0.0798, 'learning_rate': 2.626567551786944e-05, 'epoch': 0.34}\n",
      "{'loss': 0.0805, 'learning_rate': 2.6195958134711418e-05, 'epoch': 0.35}\n",
      "{'loss': 0.0794, 'learning_rate': 2.6126240751553395e-05, 'epoch': 0.35}\n",
      "{'loss': 0.0796, 'learning_rate': 2.605652336839537e-05, 'epoch': 0.35}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea733770a10411ea3ac54073197606d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07168968766927719, 'eval_rouge1': 72.4253, 'eval_rouge2': 45.073, 'eval_rougeL': 72.4105, 'eval_rougeLsum': 72.3998, 'eval_gen_len': 7.0696, 'eval_runtime': 2375.4947, 'eval_samples_per_second': 10.17, 'eval_steps_per_second': 2.543, 'epoch': 0.35}\n",
      "{'loss': 0.0809, 'learning_rate': 2.5986805985237347e-05, 'epoch': 0.35}\n",
      "{'loss': 0.0821, 'learning_rate': 2.5917088602079323e-05, 'epoch': 0.35}\n",
      "{'loss': 0.0826, 'learning_rate': 2.58473712189213e-05, 'epoch': 0.35}\n",
      "{'loss': 0.0805, 'learning_rate': 2.5777653835763276e-05, 'epoch': 0.36}\n",
      "{'loss': 0.0796, 'learning_rate': 2.5707936452605252e-05, 'epoch': 0.36}\n",
      "{'loss': 0.0809, 'learning_rate': 2.563821906944723e-05, 'epoch': 0.36}\n",
      "{'loss': 0.0804, 'learning_rate': 2.5568501686289208e-05, 'epoch': 0.36}\n",
      "{'loss': 0.0801, 'learning_rate': 2.5498784303131184e-05, 'epoch': 0.36}\n",
      "{'loss': 0.0825, 'learning_rate': 2.542906691997316e-05, 'epoch': 0.36}\n",
      "{'loss': 0.0798, 'learning_rate': 2.5359349536815137e-05, 'epoch': 0.37}\n",
      "{'loss': 0.0799, 'learning_rate': 2.5289632153657113e-05, 'epoch': 0.37}\n",
      "{'loss': 0.0758, 'learning_rate': 2.521991477049909e-05, 'epoch': 0.37}\n",
      "{'loss': 0.0806, 'learning_rate': 2.5150197387341066e-05, 'epoch': 0.37}\n",
      "{'loss': 0.0741, 'learning_rate': 2.5080480004183042e-05, 'epoch': 0.37}\n",
      "{'loss': 0.0827, 'learning_rate': 2.501076262102502e-05, 'epoch': 0.37}\n",
      "{'loss': 0.0844, 'learning_rate': 2.4941045237866998e-05, 'epoch': 0.38}\n",
      "{'loss': 0.0767, 'learning_rate': 2.4871327854708977e-05, 'epoch': 0.38}\n",
      "{'loss': 0.0795, 'learning_rate': 2.4801610471550954e-05, 'epoch': 0.38}\n",
      "{'loss': 0.0753, 'learning_rate': 2.473189308839293e-05, 'epoch': 0.38}\n",
      "{'loss': 0.0804, 'learning_rate': 2.4662175705234906e-05, 'epoch': 0.38}\n",
      "{'loss': 0.0783, 'learning_rate': 2.4592458322076886e-05, 'epoch': 0.39}\n",
      "{'loss': 0.0819, 'learning_rate': 2.4522740938918862e-05, 'epoch': 0.39}\n",
      "{'loss': 0.0819, 'learning_rate': 2.445302355576084e-05, 'epoch': 0.39}\n",
      "{'loss': 0.0792, 'learning_rate': 2.4383306172602815e-05, 'epoch': 0.39}\n",
      "{'loss': 0.077, 'learning_rate': 2.431358878944479e-05, 'epoch': 0.39}\n",
      "{'loss': 0.079, 'learning_rate': 2.4243871406286767e-05, 'epoch': 0.39}\n",
      "{'loss': 0.0772, 'learning_rate': 2.4174154023128743e-05, 'epoch': 0.4}\n",
      "{'loss': 0.077, 'learning_rate': 2.410443663997072e-05, 'epoch': 0.4}\n",
      "{'loss': 0.0737, 'learning_rate': 2.4034719256812696e-05, 'epoch': 0.4}\n",
      "{'loss': 0.0731, 'learning_rate': 2.3965001873654676e-05, 'epoch': 0.4}\n",
      "{'loss': 0.075, 'learning_rate': 2.3895284490496652e-05, 'epoch': 0.4}\n",
      "{'loss': 0.0747, 'learning_rate': 2.3825567107338628e-05, 'epoch': 0.4}\n",
      "{'loss': 0.0745, 'learning_rate': 2.3755849724180604e-05, 'epoch': 0.41}\n",
      "{'loss': 0.0729, 'learning_rate': 2.368613234102258e-05, 'epoch': 0.41}\n",
      "{'loss': 0.0755, 'learning_rate': 2.3616414957864557e-05, 'epoch': 0.41}\n",
      "{'loss': 0.0697, 'learning_rate': 2.3546697574706533e-05, 'epoch': 0.41}\n",
      "{'loss': 0.0724, 'learning_rate': 2.347698019154851e-05, 'epoch': 0.41}\n",
      "{'loss': 0.0759, 'learning_rate': 2.3407262808390486e-05, 'epoch': 0.41}\n",
      "{'loss': 0.0816, 'learning_rate': 2.3337545425232465e-05, 'epoch': 0.42}\n",
      "{'loss': 0.0825, 'learning_rate': 2.326782804207444e-05, 'epoch': 0.42}\n",
      "{'loss': 0.0753, 'learning_rate': 2.3198110658916418e-05, 'epoch': 0.42}\n",
      "{'loss': 0.076, 'learning_rate': 2.3128393275758398e-05, 'epoch': 0.42}\n",
      "{'loss': 0.0787, 'learning_rate': 2.3058675892600374e-05, 'epoch': 0.42}\n",
      "{'loss': 0.0734, 'learning_rate': 2.2988958509442353e-05, 'epoch': 0.43}\n",
      "{'loss': 0.0776, 'learning_rate': 2.291924112628433e-05, 'epoch': 0.43}\n",
      "{'loss': 0.0768, 'learning_rate': 2.2849523743126306e-05, 'epoch': 0.43}\n",
      "{'loss': 0.0801, 'learning_rate': 2.2779806359968282e-05, 'epoch': 0.43}\n",
      "{'loss': 0.0738, 'learning_rate': 2.271008897681026e-05, 'epoch': 0.43}\n",
      "{'loss': 0.0769, 'learning_rate': 2.2640371593652235e-05, 'epoch': 0.43}\n",
      "{'loss': 0.0759, 'learning_rate': 2.257065421049421e-05, 'epoch': 0.44}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64eeb48cdc1d47aa83fd1def87399bcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06636657565832138, 'eval_rouge1': 74.4298, 'eval_rouge2': 47.1037, 'eval_rougeL': 74.4024, 'eval_rougeLsum': 74.3765, 'eval_gen_len': 6.7005, 'eval_runtime': 2313.8479, 'eval_samples_per_second': 10.441, 'eval_steps_per_second': 2.61, 'epoch': 0.44}\n",
      "{'loss': 0.0732, 'learning_rate': 2.2500936827336187e-05, 'epoch': 0.44}\n",
      "{'loss': 0.0792, 'learning_rate': 2.2431219444178164e-05, 'epoch': 0.44}\n",
      "{'loss': 0.0692, 'learning_rate': 2.2361502061020143e-05, 'epoch': 0.44}\n",
      "{'loss': 0.08, 'learning_rate': 2.229178467786212e-05, 'epoch': 0.44}\n",
      "{'loss': 0.0744, 'learning_rate': 2.2222067294704096e-05, 'epoch': 0.44}\n",
      "{'loss': 0.0711, 'learning_rate': 2.2152349911546072e-05, 'epoch': 0.45}\n",
      "{'loss': 0.0768, 'learning_rate': 2.2082632528388048e-05, 'epoch': 0.45}\n",
      "{'loss': 0.0757, 'learning_rate': 2.2012915145230024e-05, 'epoch': 0.45}\n",
      "{'loss': 0.0698, 'learning_rate': 2.1943197762072e-05, 'epoch': 0.45}\n",
      "{'loss': 0.0726, 'learning_rate': 2.1873480378913977e-05, 'epoch': 0.45}\n",
      "{'loss': 0.0776, 'learning_rate': 2.1803762995755953e-05, 'epoch': 0.45}\n",
      "{'loss': 0.0738, 'learning_rate': 2.1734045612597933e-05, 'epoch': 0.46}\n",
      "{'loss': 0.0763, 'learning_rate': 2.166432822943991e-05, 'epoch': 0.46}\n",
      "{'loss': 0.072, 'learning_rate': 2.1594610846281885e-05, 'epoch': 0.46}\n",
      "{'loss': 0.0702, 'learning_rate': 2.152489346312386e-05, 'epoch': 0.46}\n",
      "{'loss': 0.0708, 'learning_rate': 2.1455176079965838e-05, 'epoch': 0.46}\n",
      "{'loss': 0.0689, 'learning_rate': 2.1385458696807818e-05, 'epoch': 0.47}\n",
      "{'loss': 0.067, 'learning_rate': 2.1315741313649797e-05, 'epoch': 0.47}\n",
      "{'loss': 0.0791, 'learning_rate': 2.1246023930491774e-05, 'epoch': 0.47}\n",
      "{'loss': 0.0723, 'learning_rate': 2.117630654733375e-05, 'epoch': 0.47}\n",
      "{'loss': 0.0681, 'learning_rate': 2.1106589164175726e-05, 'epoch': 0.47}\n",
      "{'loss': 0.0687, 'learning_rate': 2.1036871781017702e-05, 'epoch': 0.47}\n",
      "{'loss': 0.0739, 'learning_rate': 2.096715439785968e-05, 'epoch': 0.48}\n",
      "{'loss': 0.0706, 'learning_rate': 2.0897437014701655e-05, 'epoch': 0.48}\n",
      "{'loss': 0.0752, 'learning_rate': 2.082771963154363e-05, 'epoch': 0.48}\n",
      "{'loss': 0.0696, 'learning_rate': 2.075800224838561e-05, 'epoch': 0.48}\n",
      "{'loss': 0.0725, 'learning_rate': 2.0688284865227587e-05, 'epoch': 0.48}\n",
      "{'loss': 0.062, 'learning_rate': 2.0618567482069563e-05, 'epoch': 0.48}\n",
      "{'loss': 0.0659, 'learning_rate': 2.054885009891154e-05, 'epoch': 0.49}\n",
      "{'loss': 0.0744, 'learning_rate': 2.0479132715753516e-05, 'epoch': 0.49}\n",
      "{'loss': 0.0728, 'learning_rate': 2.0409415332595492e-05, 'epoch': 0.49}\n",
      "{'loss': 0.0642, 'learning_rate': 2.0339697949437468e-05, 'epoch': 0.49}\n",
      "{'loss': 0.0675, 'learning_rate': 2.0269980566279445e-05, 'epoch': 0.49}\n",
      "{'loss': 0.0709, 'learning_rate': 2.020026318312142e-05, 'epoch': 0.49}\n",
      "{'loss': 0.0667, 'learning_rate': 2.01305457999634e-05, 'epoch': 0.5}\n",
      "{'loss': 0.0713, 'learning_rate': 2.0060828416805377e-05, 'epoch': 0.5}\n",
      "{'loss': 0.0736, 'learning_rate': 1.9991111033647353e-05, 'epoch': 0.5}\n",
      "{'loss': 0.0701, 'learning_rate': 1.9921393650489333e-05, 'epoch': 0.5}\n",
      "{'loss': 0.0709, 'learning_rate': 1.985167626733131e-05, 'epoch': 0.5}\n",
      "{'loss': 0.0676, 'learning_rate': 1.9781958884173285e-05, 'epoch': 0.51}\n",
      "{'loss': 0.0678, 'learning_rate': 1.971224150101526e-05, 'epoch': 0.51}\n",
      "{'loss': 0.073, 'learning_rate': 1.9642524117857238e-05, 'epoch': 0.51}\n",
      "{'loss': 0.0732, 'learning_rate': 1.9572806734699214e-05, 'epoch': 0.51}\n",
      "{'loss': 0.0682, 'learning_rate': 1.950308935154119e-05, 'epoch': 0.51}\n",
      "{'loss': 0.0738, 'learning_rate': 1.9433371968383166e-05, 'epoch': 0.51}\n",
      "{'loss': 0.0676, 'learning_rate': 1.9363654585225146e-05, 'epoch': 0.52}\n",
      "{'loss': 0.0701, 'learning_rate': 1.9293937202067122e-05, 'epoch': 0.52}\n",
      "{'loss': 0.0699, 'learning_rate': 1.92242198189091e-05, 'epoch': 0.52}\n",
      "{'loss': 0.0656, 'learning_rate': 1.9154502435751078e-05, 'epoch': 0.52}\n",
      "{'loss': 0.0673, 'learning_rate': 1.9084785052593055e-05, 'epoch': 0.52}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b088cb8d13944a0a976057a2c3fc7d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.061216529458761215, 'eval_rouge1': 76.7897, 'eval_rouge2': 48.9331, 'eval_rougeL': 76.7869, 'eval_rougeLsum': 76.7643, 'eval_gen_len': 6.8905, 'eval_runtime': 2356.2459, 'eval_samples_per_second': 10.253, 'eval_steps_per_second': 2.563, 'epoch': 0.52}\n",
      "{'loss': 0.0688, 'learning_rate': 1.901506766943503e-05, 'epoch': 0.52}\n",
      "{'loss': 0.0689, 'learning_rate': 1.8945350286277007e-05, 'epoch': 0.53}\n",
      "{'loss': 0.0684, 'learning_rate': 1.8875632903118983e-05, 'epoch': 0.53}\n",
      "{'loss': 0.0706, 'learning_rate': 1.880591551996096e-05, 'epoch': 0.53}\n",
      "{'loss': 0.0631, 'learning_rate': 1.8736198136802936e-05, 'epoch': 0.53}\n",
      "{'loss': 0.0676, 'learning_rate': 1.8666480753644912e-05, 'epoch': 0.53}\n",
      "{'loss': 0.0658, 'learning_rate': 1.859676337048689e-05, 'epoch': 0.54}\n",
      "{'loss': 0.071, 'learning_rate': 1.8527045987328868e-05, 'epoch': 0.54}\n",
      "{'loss': 0.0662, 'learning_rate': 1.8457328604170844e-05, 'epoch': 0.54}\n",
      "{'loss': 0.0712, 'learning_rate': 1.838761122101282e-05, 'epoch': 0.54}\n",
      "{'loss': 0.0667, 'learning_rate': 1.8317893837854797e-05, 'epoch': 0.54}\n",
      "{'loss': 0.0679, 'learning_rate': 1.8248176454696776e-05, 'epoch': 0.54}\n",
      "{'loss': 0.0673, 'learning_rate': 1.8178459071538753e-05, 'epoch': 0.55}\n",
      "{'loss': 0.0639, 'learning_rate': 1.810874168838073e-05, 'epoch': 0.55}\n",
      "{'loss': 0.0679, 'learning_rate': 1.8039024305222705e-05, 'epoch': 0.55}\n",
      "{'loss': 0.0678, 'learning_rate': 1.796930692206468e-05, 'epoch': 0.55}\n",
      "{'loss': 0.0671, 'learning_rate': 1.7899589538906658e-05, 'epoch': 0.55}\n",
      "{'loss': 0.0652, 'learning_rate': 1.7829872155748634e-05, 'epoch': 0.55}\n",
      "{'loss': 0.0688, 'learning_rate': 1.7760154772590614e-05, 'epoch': 0.56}\n",
      "{'loss': 0.0642, 'learning_rate': 1.769043738943259e-05, 'epoch': 0.56}\n",
      "{'loss': 0.0648, 'learning_rate': 1.7620720006274566e-05, 'epoch': 0.56}\n",
      "{'loss': 0.0594, 'learning_rate': 1.7551002623116542e-05, 'epoch': 0.56}\n",
      "{'loss': 0.0713, 'learning_rate': 1.748128523995852e-05, 'epoch': 0.56}\n",
      "{'loss': 0.0681, 'learning_rate': 1.7411567856800495e-05, 'epoch': 0.56}\n",
      "{'loss': 0.0645, 'learning_rate': 1.7341850473642475e-05, 'epoch': 0.57}\n",
      "{'loss': 0.0695, 'learning_rate': 1.727213309048445e-05, 'epoch': 0.57}\n",
      "{'loss': 0.0613, 'learning_rate': 1.7202415707326427e-05, 'epoch': 0.57}\n",
      "{'loss': 0.0644, 'learning_rate': 1.7132698324168403e-05, 'epoch': 0.57}\n",
      "{'loss': 0.0675, 'learning_rate': 1.706298094101038e-05, 'epoch': 0.57}\n",
      "{'loss': 0.0652, 'learning_rate': 1.6993263557852356e-05, 'epoch': 0.58}\n",
      "{'loss': 0.069, 'learning_rate': 1.6923546174694336e-05, 'epoch': 0.58}\n",
      "{'loss': 0.0716, 'learning_rate': 1.6853828791536312e-05, 'epoch': 0.58}\n",
      "{'loss': 0.0655, 'learning_rate': 1.6784111408378288e-05, 'epoch': 0.58}\n",
      "{'loss': 0.0641, 'learning_rate': 1.6714394025220264e-05, 'epoch': 0.58}\n",
      "{'loss': 0.0614, 'learning_rate': 1.664467664206224e-05, 'epoch': 0.58}\n",
      "{'loss': 0.063, 'learning_rate': 1.6574959258904217e-05, 'epoch': 0.59}\n",
      "{'loss': 0.0628, 'learning_rate': 1.6505241875746197e-05, 'epoch': 0.59}\n",
      "{'loss': 0.0707, 'learning_rate': 1.6435524492588173e-05, 'epoch': 0.59}\n",
      "{'loss': 0.0656, 'learning_rate': 1.636580710943015e-05, 'epoch': 0.59}\n",
      "{'loss': 0.0592, 'learning_rate': 1.6296089726272125e-05, 'epoch': 0.59}\n",
      "{'loss': 0.0646, 'learning_rate': 1.62263723431141e-05, 'epoch': 0.59}\n",
      "{'loss': 0.0676, 'learning_rate': 1.615665495995608e-05, 'epoch': 0.6}\n",
      "{'loss': 0.0696, 'learning_rate': 1.6086937576798058e-05, 'epoch': 0.6}\n",
      "{'loss': 0.0652, 'learning_rate': 1.6017220193640034e-05, 'epoch': 0.6}\n",
      "{'loss': 0.0715, 'learning_rate': 1.594750281048201e-05, 'epoch': 0.6}\n",
      "{'loss': 0.0691, 'learning_rate': 1.5877785427323986e-05, 'epoch': 0.6}\n",
      "{'loss': 0.0649, 'learning_rate': 1.5808068044165963e-05, 'epoch': 0.6}\n",
      "{'loss': 0.0636, 'learning_rate': 1.573835066100794e-05, 'epoch': 0.61}\n",
      "{'loss': 0.0653, 'learning_rate': 1.5668633277849915e-05, 'epoch': 0.61}\n",
      "{'loss': 0.0662, 'learning_rate': 1.5598915894691895e-05, 'epoch': 0.61}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f8fcf29a8934cc18b8c6de1e411dbad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.058183714747428894, 'eval_rouge1': 77.4453, 'eval_rouge2': 48.9871, 'eval_rougeL': 77.4342, 'eval_rougeLsum': 77.3989, 'eval_gen_len': 7.0871, 'eval_runtime': 2589.2305, 'eval_samples_per_second': 9.33, 'eval_steps_per_second': 2.333, 'epoch': 0.61}\n",
      "{'loss': 0.0663, 'learning_rate': 1.552919851153387e-05, 'epoch': 0.61}\n",
      "{'loss': 0.0618, 'learning_rate': 1.5459481128375847e-05, 'epoch': 0.61}\n",
      "{'loss': 0.0681, 'learning_rate': 1.5389763745217824e-05, 'epoch': 0.62}\n",
      "{'loss': 0.0659, 'learning_rate': 1.5320046362059803e-05, 'epoch': 0.62}\n",
      "{'loss': 0.0664, 'learning_rate': 1.5250328978901778e-05, 'epoch': 0.62}\n",
      "{'loss': 0.0722, 'learning_rate': 1.5180611595743756e-05, 'epoch': 0.62}\n",
      "{'loss': 0.0658, 'learning_rate': 1.5110894212585732e-05, 'epoch': 0.62}\n",
      "{'loss': 0.0619, 'learning_rate': 1.5041176829427708e-05, 'epoch': 0.62}\n",
      "{'loss': 0.0628, 'learning_rate': 1.4971459446269684e-05, 'epoch': 0.63}\n",
      "{'loss': 0.0713, 'learning_rate': 1.4901742063111662e-05, 'epoch': 0.63}\n",
      "{'loss': 0.0619, 'learning_rate': 1.4832024679953639e-05, 'epoch': 0.63}\n",
      "{'loss': 0.0638, 'learning_rate': 1.4762307296795615e-05, 'epoch': 0.63}\n",
      "{'loss': 0.0662, 'learning_rate': 1.4692589913637595e-05, 'epoch': 0.63}\n",
      "{'loss': 0.0607, 'learning_rate': 1.4622872530479571e-05, 'epoch': 0.63}\n",
      "{'loss': 0.0641, 'learning_rate': 1.4553155147321547e-05, 'epoch': 0.64}\n",
      "{'loss': 0.0663, 'learning_rate': 1.4483437764163523e-05, 'epoch': 0.64}\n",
      "{'loss': 0.0663, 'learning_rate': 1.44137203810055e-05, 'epoch': 0.64}\n",
      "{'loss': 0.0604, 'learning_rate': 1.4344002997847478e-05, 'epoch': 0.64}\n",
      "{'loss': 0.0595, 'learning_rate': 1.4274285614689454e-05, 'epoch': 0.64}\n",
      "{'loss': 0.0618, 'learning_rate': 1.420456823153143e-05, 'epoch': 0.64}\n",
      "{'loss': 0.0591, 'learning_rate': 1.4134850848373406e-05, 'epoch': 0.65}\n",
      "{'loss': 0.0635, 'learning_rate': 1.4065133465215384e-05, 'epoch': 0.65}\n",
      "{'loss': 0.0614, 'learning_rate': 1.399541608205736e-05, 'epoch': 0.65}\n",
      "{'loss': 0.0632, 'learning_rate': 1.3925698698899337e-05, 'epoch': 0.65}\n",
      "{'loss': 0.0624, 'learning_rate': 1.3855981315741317e-05, 'epoch': 0.65}\n",
      "{'loss': 0.0579, 'learning_rate': 1.3786263932583293e-05, 'epoch': 0.66}\n",
      "{'loss': 0.0647, 'learning_rate': 1.3716546549425269e-05, 'epoch': 0.66}\n",
      "{'loss': 0.0628, 'learning_rate': 1.3646829166267245e-05, 'epoch': 0.66}\n",
      "{'loss': 0.0643, 'learning_rate': 1.3577111783109223e-05, 'epoch': 0.66}\n",
      "{'loss': 0.0586, 'learning_rate': 1.35073943999512e-05, 'epoch': 0.66}\n",
      "{'loss': 0.0622, 'learning_rate': 1.3437677016793176e-05, 'epoch': 0.66}\n",
      "{'loss': 0.0677, 'learning_rate': 1.3367959633635152e-05, 'epoch': 0.67}\n",
      "{'loss': 0.0618, 'learning_rate': 1.3298242250477128e-05, 'epoch': 0.67}\n",
      "{'loss': 0.0619, 'learning_rate': 1.3228524867319106e-05, 'epoch': 0.67}\n",
      "{'loss': 0.0592, 'learning_rate': 1.3158807484161083e-05, 'epoch': 0.67}\n",
      "{'loss': 0.0636, 'learning_rate': 1.3089090101003059e-05, 'epoch': 0.67}\n",
      "{'loss': 0.0634, 'learning_rate': 1.3019372717845035e-05, 'epoch': 0.67}\n",
      "{'loss': 0.0614, 'learning_rate': 1.2949655334687015e-05, 'epoch': 0.68}\n",
      "{'loss': 0.0638, 'learning_rate': 1.2879937951528991e-05, 'epoch': 0.68}\n",
      "{'loss': 0.0674, 'learning_rate': 1.2810220568370967e-05, 'epoch': 0.68}\n",
      "{'loss': 0.0654, 'learning_rate': 1.2740503185212945e-05, 'epoch': 0.68}\n",
      "{'loss': 0.0618, 'learning_rate': 1.2670785802054921e-05, 'epoch': 0.68}\n",
      "{'loss': 0.0592, 'learning_rate': 1.2601068418896898e-05, 'epoch': 0.68}\n",
      "{'loss': 0.0576, 'learning_rate': 1.2531351035738874e-05, 'epoch': 0.69}\n",
      "{'loss': 0.0647, 'learning_rate': 1.2461633652580852e-05, 'epoch': 0.69}\n",
      "{'loss': 0.0594, 'learning_rate': 1.2391916269422828e-05, 'epoch': 0.69}\n",
      "{'loss': 0.0621, 'learning_rate': 1.2322198886264804e-05, 'epoch': 0.69}\n",
      "{'loss': 0.0655, 'learning_rate': 1.225248150310678e-05, 'epoch': 0.69}\n",
      "{'loss': 0.0634, 'learning_rate': 1.2182764119948759e-05, 'epoch': 0.7}\n",
      "{'loss': 0.0612, 'learning_rate': 1.2113046736790735e-05, 'epoch': 0.7}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d07031e3307d4635ac76eddc247dd91b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.055196575820446014, 'eval_rouge1': 78.6399, 'eval_rouge2': 50.8648, 'eval_rougeL': 78.6181, 'eval_rougeLsum': 78.592, 'eval_gen_len': 6.8921, 'eval_runtime': 2585.1367, 'eval_samples_per_second': 9.345, 'eval_steps_per_second': 2.336, 'epoch': 0.7}\n",
      "{'loss': 0.0631, 'learning_rate': 1.2043329353632713e-05, 'epoch': 0.7}\n",
      "{'loss': 0.0635, 'learning_rate': 1.197361197047469e-05, 'epoch': 0.7}\n",
      "{'loss': 0.0646, 'learning_rate': 1.1903894587316667e-05, 'epoch': 0.7}\n",
      "{'loss': 0.0607, 'learning_rate': 1.1834177204158643e-05, 'epoch': 0.7}\n",
      "{'loss': 0.0613, 'learning_rate': 1.176445982100062e-05, 'epoch': 0.71}\n",
      "{'loss': 0.0632, 'learning_rate': 1.1694742437842596e-05, 'epoch': 0.71}\n",
      "{'loss': 0.0666, 'learning_rate': 1.1625025054684574e-05, 'epoch': 0.71}\n",
      "{'loss': 0.0639, 'learning_rate': 1.155530767152655e-05, 'epoch': 0.71}\n",
      "{'loss': 0.061, 'learning_rate': 1.1485590288368526e-05, 'epoch': 0.71}\n",
      "{'loss': 0.0653, 'learning_rate': 1.1415872905210503e-05, 'epoch': 0.71}\n",
      "{'loss': 0.0647, 'learning_rate': 1.134615552205248e-05, 'epoch': 0.72}\n",
      "{'loss': 0.0627, 'learning_rate': 1.1276438138894457e-05, 'epoch': 0.72}\n",
      "{'loss': 0.059, 'learning_rate': 1.1206720755736433e-05, 'epoch': 0.72}\n",
      "{'loss': 0.0633, 'learning_rate': 1.1137003372578413e-05, 'epoch': 0.72}\n",
      "{'loss': 0.0603, 'learning_rate': 1.1067285989420389e-05, 'epoch': 0.72}\n",
      "{'loss': 0.0619, 'learning_rate': 1.0997568606262365e-05, 'epoch': 0.73}\n",
      "{'loss': 0.0597, 'learning_rate': 1.0927851223104342e-05, 'epoch': 0.73}\n",
      "{'loss': 0.0622, 'learning_rate': 1.085813383994632e-05, 'epoch': 0.73}\n",
      "{'loss': 0.0636, 'learning_rate': 1.0788416456788296e-05, 'epoch': 0.73}\n",
      "{'loss': 0.0621, 'learning_rate': 1.0718699073630272e-05, 'epoch': 0.73}\n",
      "{'loss': 0.064, 'learning_rate': 1.0648981690472248e-05, 'epoch': 0.73}\n",
      "{'loss': 0.0572, 'learning_rate': 1.0579264307314225e-05, 'epoch': 0.74}\n",
      "{'loss': 0.0605, 'learning_rate': 1.0509546924156203e-05, 'epoch': 0.74}\n",
      "{'loss': 0.0608, 'learning_rate': 1.0439829540998179e-05, 'epoch': 0.74}\n",
      "{'loss': 0.0609, 'learning_rate': 1.0370112157840155e-05, 'epoch': 0.74}\n",
      "{'loss': 0.0535, 'learning_rate': 1.0300394774682135e-05, 'epoch': 0.74}\n",
      "{'loss': 0.0597, 'learning_rate': 1.0230677391524111e-05, 'epoch': 0.74}\n",
      "{'loss': 0.0618, 'learning_rate': 1.0160960008366087e-05, 'epoch': 0.75}\n",
      "{'loss': 0.0638, 'learning_rate': 1.0091242625208063e-05, 'epoch': 0.75}\n",
      "{'loss': 0.0625, 'learning_rate': 1.0021525242050041e-05, 'epoch': 0.75}\n",
      "{'loss': 0.064, 'learning_rate': 9.951807858892018e-06, 'epoch': 0.75}\n",
      "{'loss': 0.0573, 'learning_rate': 9.882090475733994e-06, 'epoch': 0.75}\n",
      "{'loss': 0.0603, 'learning_rate': 9.81237309257597e-06, 'epoch': 0.75}\n",
      "{'loss': 0.0627, 'learning_rate': 9.742655709417948e-06, 'epoch': 0.76}\n",
      "{'loss': 0.0629, 'learning_rate': 9.672938326259924e-06, 'epoch': 0.76}\n",
      "{'loss': 0.057, 'learning_rate': 9.603220943101902e-06, 'epoch': 0.76}\n",
      "{'loss': 0.06, 'learning_rate': 9.533503559943879e-06, 'epoch': 0.76}\n",
      "{'loss': 0.0619, 'learning_rate': 9.463786176785855e-06, 'epoch': 0.76}\n",
      "{'loss': 0.0618, 'learning_rate': 9.394068793627831e-06, 'epoch': 0.77}\n",
      "{'loss': 0.0611, 'learning_rate': 9.324351410469809e-06, 'epoch': 0.77}\n",
      "{'loss': 0.0608, 'learning_rate': 9.254634027311785e-06, 'epoch': 0.77}\n",
      "{'loss': 0.0589, 'learning_rate': 9.184916644153763e-06, 'epoch': 0.77}\n",
      "{'loss': 0.058, 'learning_rate': 9.11519926099574e-06, 'epoch': 0.77}\n",
      "{'loss': 0.0593, 'learning_rate': 9.045481877837716e-06, 'epoch': 0.77}\n",
      "{'loss': 0.0572, 'learning_rate': 8.975764494679692e-06, 'epoch': 0.78}\n",
      "{'loss': 0.0623, 'learning_rate': 8.90604711152167e-06, 'epoch': 0.78}\n",
      "{'loss': 0.0624, 'learning_rate': 8.836329728363646e-06, 'epoch': 0.78}\n",
      "{'loss': 0.0598, 'learning_rate': 8.766612345205623e-06, 'epoch': 0.78}\n",
      "{'loss': 0.0611, 'learning_rate': 8.6968949620476e-06, 'epoch': 0.78}\n",
      "{'loss': 0.0622, 'learning_rate': 8.627177578889577e-06, 'epoch': 0.78}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6cc7f8f76f44f8b9c23ec3d67b265e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.05327032133936882, 'eval_rouge1': 79.0955, 'eval_rouge2': 51.4789, 'eval_rougeL': 79.0714, 'eval_rougeLsum': 79.0479, 'eval_gen_len': 7.0599, 'eval_runtime': 2545.6612, 'eval_samples_per_second': 9.49, 'eval_steps_per_second': 2.373, 'epoch': 0.78}\n",
      "{'loss': 0.0595, 'learning_rate': 8.557460195731555e-06, 'epoch': 0.79}\n",
      "{'loss': 0.059, 'learning_rate': 8.487742812573531e-06, 'epoch': 0.79}\n",
      "{'loss': 0.0636, 'learning_rate': 8.418025429415507e-06, 'epoch': 0.79}\n",
      "{'loss': 0.0587, 'learning_rate': 8.348308046257484e-06, 'epoch': 0.79}\n",
      "{'loss': 0.0611, 'learning_rate': 8.278590663099462e-06, 'epoch': 0.79}\n",
      "{'loss': 0.0572, 'learning_rate': 8.208873279941438e-06, 'epoch': 0.79}\n",
      "{'loss': 0.0629, 'learning_rate': 8.139155896783416e-06, 'epoch': 0.8}\n",
      "{'loss': 0.0647, 'learning_rate': 8.069438513625392e-06, 'epoch': 0.8}\n",
      "{'loss': 0.0607, 'learning_rate': 7.999721130467368e-06, 'epoch': 0.8}\n",
      "{'loss': 0.062, 'learning_rate': 7.930003747309345e-06, 'epoch': 0.8}\n",
      "{'loss': 0.058, 'learning_rate': 7.860286364151322e-06, 'epoch': 0.8}\n",
      "{'loss': 0.0584, 'learning_rate': 7.790568980993299e-06, 'epoch': 0.81}\n",
      "{'loss': 0.0601, 'learning_rate': 7.720851597835277e-06, 'epoch': 0.81}\n",
      "{'loss': 0.0582, 'learning_rate': 7.651134214677253e-06, 'epoch': 0.81}\n",
      "{'loss': 0.0585, 'learning_rate': 7.581416831519229e-06, 'epoch': 0.81}\n",
      "{'loss': 0.0581, 'learning_rate': 7.511699448361206e-06, 'epoch': 0.81}\n",
      "{'loss': 0.0562, 'learning_rate': 7.4419820652031826e-06, 'epoch': 0.81}\n",
      "{'loss': 0.0566, 'learning_rate': 7.3722646820451605e-06, 'epoch': 0.82}\n",
      "{'loss': 0.06, 'learning_rate': 7.302547298887137e-06, 'epoch': 0.82}\n",
      "{'loss': 0.0581, 'learning_rate': 7.232829915729114e-06, 'epoch': 0.82}\n",
      "{'loss': 0.0615, 'learning_rate': 7.16311253257109e-06, 'epoch': 0.82}\n",
      "{'loss': 0.0567, 'learning_rate': 7.093395149413067e-06, 'epoch': 0.82}\n",
      "{'loss': 0.0576, 'learning_rate': 7.0236777662550435e-06, 'epoch': 0.82}\n",
      "{'loss': 0.0586, 'learning_rate': 6.9539603830970215e-06, 'epoch': 0.83}\n",
      "{'loss': 0.0595, 'learning_rate': 6.884242999938998e-06, 'epoch': 0.83}\n",
      "{'loss': 0.0616, 'learning_rate': 6.814525616780975e-06, 'epoch': 0.83}\n",
      "{'loss': 0.0569, 'learning_rate': 6.744808233622951e-06, 'epoch': 0.83}\n",
      "{'loss': 0.0603, 'learning_rate': 6.675090850464928e-06, 'epoch': 0.83}\n",
      "{'loss': 0.0562, 'learning_rate': 6.6053734673069045e-06, 'epoch': 0.83}\n",
      "{'loss': 0.0588, 'learning_rate': 6.5356560841488824e-06, 'epoch': 0.84}\n",
      "{'loss': 0.0581, 'learning_rate': 6.4659387009908596e-06, 'epoch': 0.84}\n",
      "{'loss': 0.0572, 'learning_rate': 6.396221317832836e-06, 'epoch': 0.84}\n",
      "{'loss': 0.0567, 'learning_rate': 6.326503934674812e-06, 'epoch': 0.84}\n",
      "{'loss': 0.0539, 'learning_rate': 6.256786551516789e-06, 'epoch': 0.84}\n",
      "{'loss': 0.0551, 'learning_rate': 6.1870691683587654e-06, 'epoch': 0.85}\n",
      "{'loss': 0.0603, 'learning_rate': 6.1173517852007426e-06, 'epoch': 0.85}\n",
      "{'loss': 0.0552, 'learning_rate': 6.0476344020427205e-06, 'epoch': 0.85}\n",
      "{'loss': 0.0564, 'learning_rate': 5.977917018884697e-06, 'epoch': 0.85}\n",
      "{'loss': 0.0565, 'learning_rate': 5.908199635726674e-06, 'epoch': 0.85}\n",
      "{'loss': 0.0565, 'learning_rate': 5.83848225256865e-06, 'epoch': 0.85}\n",
      "{'loss': 0.059, 'learning_rate': 5.768764869410627e-06, 'epoch': 0.86}\n",
      "{'loss': 0.0603, 'learning_rate': 5.6990474862526035e-06, 'epoch': 0.86}\n",
      "{'loss': 0.0601, 'learning_rate': 5.6293301030945815e-06, 'epoch': 0.86}\n",
      "{'loss': 0.0606, 'learning_rate': 5.559612719936558e-06, 'epoch': 0.86}\n",
      "{'loss': 0.0532, 'learning_rate': 5.489895336778535e-06, 'epoch': 0.86}\n",
      "{'loss': 0.0546, 'learning_rate': 5.420177953620511e-06, 'epoch': 0.86}\n",
      "{'loss': 0.0554, 'learning_rate': 5.350460570462488e-06, 'epoch': 0.87}\n",
      "{'loss': 0.0539, 'learning_rate': 5.2807431873044645e-06, 'epoch': 0.87}\n",
      "{'loss': 0.0581, 'learning_rate': 5.2110258041464424e-06, 'epoch': 0.87}\n",
      "{'loss': 0.0593, 'learning_rate': 5.141308420988419e-06, 'epoch': 0.87}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "434a5c6abf744b3aacdc00dd13c030d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.05219770595431328, 'eval_rouge1': 79.9518, 'eval_rouge2': 52.1942, 'eval_rougeL': 79.9293, 'eval_rougeLsum': 79.9205, 'eval_gen_len': 7.0773, 'eval_runtime': 2885.9647, 'eval_samples_per_second': 8.371, 'eval_steps_per_second': 2.093, 'epoch': 0.87}\n",
      "{'loss': 0.0573, 'learning_rate': 5.071591037830396e-06, 'epoch': 0.87}\n",
      "{'loss': 0.0569, 'learning_rate': 5.001873654672372e-06, 'epoch': 0.87}\n",
      "{'loss': 0.0603, 'learning_rate': 4.932156271514349e-06, 'epoch': 0.88}\n",
      "{'loss': 0.062, 'learning_rate': 4.862438888356326e-06, 'epoch': 0.88}\n",
      "{'loss': 0.0586, 'learning_rate': 4.7927215051983025e-06, 'epoch': 0.88}\n",
      "{'loss': 0.0584, 'learning_rate': 4.72300412204028e-06, 'epoch': 0.88}\n",
      "{'loss': 0.0558, 'learning_rate': 4.653286738882257e-06, 'epoch': 0.88}\n",
      "{'loss': 0.0545, 'learning_rate': 4.583569355724233e-06, 'epoch': 0.89}\n",
      "{'loss': 0.062, 'learning_rate': 4.51385197256621e-06, 'epoch': 0.89}\n",
      "{'loss': 0.0557, 'learning_rate': 4.444134589408186e-06, 'epoch': 0.89}\n",
      "{'loss': 0.0572, 'learning_rate': 4.3744172062501635e-06, 'epoch': 0.89}\n",
      "{'loss': 0.0597, 'learning_rate': 4.304699823092141e-06, 'epoch': 0.89}\n",
      "{'loss': 0.0613, 'learning_rate': 4.234982439934117e-06, 'epoch': 0.89}\n",
      "{'loss': 0.0605, 'learning_rate': 4.165265056776094e-06, 'epoch': 0.9}\n",
      "{'loss': 0.0551, 'learning_rate': 4.095547673618071e-06, 'epoch': 0.9}\n",
      "{'loss': 0.0598, 'learning_rate': 4.025830290460047e-06, 'epoch': 0.9}\n",
      "{'loss': 0.0556, 'learning_rate': 3.956112907302025e-06, 'epoch': 0.9}\n",
      "{'loss': 0.0604, 'learning_rate': 3.8863955241440016e-06, 'epoch': 0.9}\n",
      "{'loss': 0.0582, 'learning_rate': 3.816678140985978e-06, 'epoch': 0.9}\n",
      "{'loss': 0.0618, 'learning_rate': 3.7469607578279554e-06, 'epoch': 0.91}\n",
      "{'loss': 0.0567, 'learning_rate': 3.677243374669932e-06, 'epoch': 0.91}\n",
      "{'loss': 0.0617, 'learning_rate': 3.6075259915119087e-06, 'epoch': 0.91}\n",
      "{'loss': 0.0617, 'learning_rate': 3.537808608353886e-06, 'epoch': 0.91}\n",
      "{'loss': 0.0575, 'learning_rate': 3.4680912251958625e-06, 'epoch': 0.91}\n",
      "{'loss': 0.0556, 'learning_rate': 3.398373842037839e-06, 'epoch': 0.92}\n",
      "{'loss': 0.0605, 'learning_rate': 3.3286564588798163e-06, 'epoch': 0.92}\n",
      "{'loss': 0.0595, 'learning_rate': 3.258939075721793e-06, 'epoch': 0.92}\n",
      "{'loss': 0.055, 'learning_rate': 3.1892216925637697e-06, 'epoch': 0.92}\n",
      "{'loss': 0.0572, 'learning_rate': 3.1195043094057464e-06, 'epoch': 0.92}\n",
      "{'loss': 0.0529, 'learning_rate': 3.0497869262477235e-06, 'epoch': 0.92}\n",
      "{'loss': 0.0553, 'learning_rate': 2.9800695430897e-06, 'epoch': 0.93}\n",
      "{'loss': 0.0595, 'learning_rate': 2.910352159931677e-06, 'epoch': 0.93}\n",
      "{'loss': 0.0557, 'learning_rate': 2.8406347767736544e-06, 'epoch': 0.93}\n",
      "{'loss': 0.0592, 'learning_rate': 2.7709173936156306e-06, 'epoch': 0.93}\n",
      "{'loss': 0.0547, 'learning_rate': 2.7012000104576073e-06, 'epoch': 0.93}\n",
      "{'loss': 0.0542, 'learning_rate': 2.631482627299585e-06, 'epoch': 0.93}\n",
      "{'loss': 0.0596, 'learning_rate': 2.5617652441415615e-06, 'epoch': 0.94}\n",
      "{'loss': 0.0537, 'learning_rate': 2.4920478609835382e-06, 'epoch': 0.94}\n",
      "{'loss': 0.0558, 'learning_rate': 2.422330477825515e-06, 'epoch': 0.94}\n",
      "{'loss': 0.0591, 'learning_rate': 2.352613094667492e-06, 'epoch': 0.94}\n",
      "{'loss': 0.0569, 'learning_rate': 2.2828957115094687e-06, 'epoch': 0.94}\n",
      "{'loss': 0.0571, 'learning_rate': 2.2131783283514454e-06, 'epoch': 0.94}\n",
      "{'loss': 0.0599, 'learning_rate': 2.1434609451934225e-06, 'epoch': 0.95}\n",
      "{'loss': 0.0572, 'learning_rate': 2.073743562035399e-06, 'epoch': 0.95}\n",
      "{'loss': 0.0543, 'learning_rate': 2.004026178877376e-06, 'epoch': 0.95}\n",
      "{'loss': 0.0594, 'learning_rate': 1.934308795719353e-06, 'epoch': 0.95}\n",
      "{'loss': 0.0606, 'learning_rate': 1.8645914125613297e-06, 'epoch': 0.95}\n",
      "{'loss': 0.0568, 'learning_rate': 1.7948740294033066e-06, 'epoch': 0.96}\n",
      "{'loss': 0.0593, 'learning_rate': 1.7251566462452835e-06, 'epoch': 0.96}\n",
      "{'loss': 0.0584, 'learning_rate': 1.6554392630872601e-06, 'epoch': 0.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ceeef7d38847b2b447039443717375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.05088723078370094, 'eval_rouge1': 80.2109, 'eval_rouge2': 52.1682, 'eval_rougeL': 80.193, 'eval_rougeLsum': 80.1796, 'eval_gen_len': 7.0882, 'eval_runtime': 2711.379, 'eval_samples_per_second': 8.91, 'eval_steps_per_second': 2.228, 'epoch': 0.96}\n",
      "{'loss': 0.0574, 'learning_rate': 1.585721879929237e-06, 'epoch': 0.96}\n",
      "{'loss': 0.0571, 'learning_rate': 1.5160044967712137e-06, 'epoch': 0.96}\n",
      "{'loss': 0.0618, 'learning_rate': 1.4462871136131906e-06, 'epoch': 0.96}\n",
      "{'loss': 0.0578, 'learning_rate': 1.3765697304551675e-06, 'epoch': 0.97}\n",
      "{'loss': 0.0605, 'learning_rate': 1.3068523472971442e-06, 'epoch': 0.97}\n",
      "{'loss': 0.0544, 'learning_rate': 1.2371349641391211e-06, 'epoch': 0.97}\n",
      "{'loss': 0.0578, 'learning_rate': 1.167417580981098e-06, 'epoch': 0.97}\n",
      "{'loss': 0.0569, 'learning_rate': 1.0977001978230747e-06, 'epoch': 0.97}\n",
      "{'loss': 0.0602, 'learning_rate': 1.0279828146650516e-06, 'epoch': 0.97}\n",
      "{'loss': 0.0538, 'learning_rate': 9.582654315070285e-07, 'epoch': 0.98}\n",
      "{'loss': 0.0538, 'learning_rate': 8.885480483490053e-07, 'epoch': 0.98}\n",
      "{'loss': 0.0575, 'learning_rate': 8.188306651909821e-07, 'epoch': 0.98}\n",
      "{'loss': 0.0542, 'learning_rate': 7.49113282032959e-07, 'epoch': 0.98}\n",
      "{'loss': 0.0522, 'learning_rate': 6.793958988749358e-07, 'epoch': 0.98}\n",
      "{'loss': 0.0529, 'learning_rate': 6.096785157169125e-07, 'epoch': 0.98}\n",
      "{'loss': 0.057, 'learning_rate': 5.399611325588894e-07, 'epoch': 0.99}\n",
      "{'loss': 0.0571, 'learning_rate': 4.7024374940086623e-07, 'epoch': 0.99}\n",
      "{'loss': 0.0536, 'learning_rate': 4.0052636624284313e-07, 'epoch': 0.99}\n",
      "{'loss': 0.0569, 'learning_rate': 3.3080898308481997e-07, 'epoch': 0.99}\n",
      "{'loss': 0.0556, 'learning_rate': 2.6109159992679676e-07, 'epoch': 0.99}\n",
      "{'loss': 0.0583, 'learning_rate': 1.913742167687736e-07, 'epoch': 1.0}\n",
      "{'loss': 0.0594, 'learning_rate': 1.2165683361075043e-07, 'epoch': 1.0}\n",
      "{'loss': 0.0519, 'learning_rate': 5.193945045272726e-08, 'epoch': 1.0}\n",
      "{'train_runtime': 76963.6092, 'train_samples_per_second': 5.964, 'train_steps_per_second': 1.491, 'train_loss': 0.08713308761251343, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=114749, training_loss=0.08713308761251343, metrics={'train_runtime': 76963.6092, 'train_samples_per_second': 5.964, 'train_steps_per_second': 1.491, 'train_loss': 0.08713308761251343, 'epoch': 1.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2349b6b14b9429b9340d37764534ec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.05088723078370094,\n",
       " 'eval_rouge1': 80.2109,\n",
       " 'eval_rouge2': 52.1682,\n",
       " 'eval_rougeL': 80.193,\n",
       " 'eval_rougeLsum': 80.1796,\n",
       " 'eval_gen_len': 7.0882,\n",
       " 'eval_runtime': 2619.9773,\n",
       " 'eval_samples_per_second': 9.221,\n",
       " 'eval_steps_per_second': 2.305,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('t5/Tabula5apiens-1epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('t5/checkpoint-52000/')\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('t5/checkpoint-52000/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\johnz\\Desktop\\scLLM\\scT5.ipynb Cell 30\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/johnz/Desktop/scLLM/scT5.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m max_input_length \u001b[39m=\u001b[39m \u001b[39m512\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/johnz/Desktop/scLLM/scT5.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m texts \u001b[39m=\u001b[39m dataset[\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m39\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/johnz/Desktop/scLLM/scT5.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#inputs = [prefix + text for text in texts]\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/johnz/Desktop/scLLM/scT5.ipynb#X36sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m inputs \u001b[39m=\u001b[39m [prefix \u001b[39m+\u001b[39m texts]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "max_input_length = 512\n",
    "texts = dataset['test']['text'][39]\n",
    "#inputs = [prefix + text for text in texts]\n",
    "inputs = [prefix + texts]\n",
    "inputs = tokenizer(inputs, max_length=max_input_length, truncation=True, return_tensors=\"pt\").to('cuda')\n",
    "output = model.generate(**inputs, num_beams=32, do_sample=True, min_length=0, max_length=64)\n",
    "decoded_output = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
    "predicted_title = nltk.sent_tokenize(decoded_output.strip())[0]\n",
    "\n",
    "print(predicted_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CD8-positive, alpha-beta cytotoxic T cell'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test']['cell_type'][39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9722: epithelial cell - epithelial cell\n",
      "7133: stratified epithelial cell - epithelial cell\n",
      "1916: stratified epithelial cell - stratified epithelial cell\n",
      "1997: CD8-positive, alpha-beta T cell - stromal cell\n",
      "10276: epithelial cell - epithelial cell\n",
      "1873: stratified epithelial cell - stratified epithelial cell\n",
      "1643: epithelial cell - epithelial cell\n",
      "15623: epithelial cell - epithelial cell\n",
      "16477: stratified epithelial cell - stratified epithelial cell\n",
      "17403: stratified epithelial cell - stratified epithelial cell\n",
      "5158: stratified epithelial cell - stratified epithelial cell\n",
      "1863: stratified epithelial cell - stratified epithelial cell\n",
      "16640: stratified epithelial cell - stratified epithelial cell\n",
      "2625: epithelial cell - epithelial cell\n",
      "6089: stratified epithelial cell - stratified epithelial cell\n",
      "2245: stratified epithelial cell - stratified epithelial cell\n",
      "2226: stratified epithelial cell - stratified epithelial cell\n",
      "7707: epithelial cell - epithelial cell\n",
      "13230: epithelial cell - epithelial cell\n",
      "3928: epithelial cell - epithelial cell\n",
      "8067: blood vessel endothelial cell - blood vessel endothelial cell\n",
      "1302: epithelial cell - stratified epithelial cell\n",
      "2686: epithelial cell - epithelial cell\n",
      "13737: stratified epithelial cell - stratified epithelial cell\n",
      "17130: stratified epithelial cell - stratified epithelial cell\n"
     ]
    }
   ],
   "source": [
    "for x in random.sample(range(0, len(dataset['test']['text'])),25):\n",
    "    max_input_length = 512\n",
    "    texts = dataset['test']['text'][x]\n",
    "    #inputs = [prefix + text for text in texts]\n",
    "    inputs = [prefix + texts]\n",
    "    inputs = tokenizer(inputs, max_length=max_input_length, truncation=True, return_tensors=\"pt\").to('cuda')\n",
    "    output = model.generate(**inputs, num_beams=32, do_sample=True, min_length=0, max_length=64)\n",
    "    decoded_output = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
    "    predicted_title = nltk.sent_tokenize(decoded_output.strip())[0]\n",
    "\n",
    "    print(str(x) + ': ' + predicted_title + ' - ' + dataset['test']['cell_type'][x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "celldl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
